<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Disaggregated Sectoral Employment Dynamics in Australia</title>
    <meta charset="utf-8" />
    <meta name="author" content="Zhixiang Yang (Elvis)" />
    <script src="libs/header-attrs-2.13/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/ninjutsu.css" rel="stylesheet" />
    <link href="libs/font-awesome-animation-1.0/font-awesome-animation-emi.css" rel="stylesheet" />
    <script src="libs/fontawesome-5.0.13/js/fontawesome-all.min.js"></script>
    <!--
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script> 
    -->
    <link rel="icon" href="images/favicon.ico"  type='image/x-icon'/>    
    <link rel="stylesheet" href="assets/animate.css" type="text/css" />
    <link rel="stylesheet" href="assets/monash-logo.css" type="text/css" />
    <link rel="stylesheet" href="assets/monash-brand.css" type="text/css" />
    <link rel="stylesheet" href="assets/monash-fonts.css" type="text/css" />
    <link rel="stylesheet" href="assets/styles.css" type="text/css" />
    <link rel="stylesheet" href="assets/custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">






background-color: #006DAE
class: middle center hide-slide-number


&lt;div class="shade_black"  style="width:60%;right:0;bottom:0;padding:10px;border: dashed 4px white;margin: auto;"&gt;
&lt;i class="fas fa-exclamation-circle"&gt;&lt;/i&gt; These slides are viewed best by Chrome and occasionally need to be refreshed if elements did not load properly. 
&lt;/div&gt;

&lt;br&gt;

.white[Press the **right arrow** to progress to the next slide!]

---


background-image: url(images/auz_workers.jpeg)
background-size: cover
class: hide-slide-number split-70 title-slide
count: false

.column.shade_black[.content[

&lt;br&gt;

# .monash-blue.outline-text[Disaggregated Sectoral Employment Dynamics in Australia]

&lt;h2 class="monash-blue2 outline-text" style="font-size: 30pt!important;"&gt;&lt;/h2&gt;

&lt;br&gt;

&lt;h2 style="font-weight:900!important;"&gt;A story of two-digit subsectors&lt;/h2&gt;

.bottom_abs.width100[

*Zhixiang Yang (Elvis)* 


Department of Econometrics and Business Statistics

<span>&lt;i class="fas  fa-envelope faa-float animated "&gt;&lt;/i&gt;</span>  zyan0056@student.monash.edu

5th October 2022

&lt;br&gt;
]


]]



&lt;div class="column transition monash-m-new delay-1s" style="clip-path:url(#swipe__clip-path);"&gt;
&lt;div class="background-image" style="background-image:url('images/large.png');background-position: center;background-size:cover;margin-left:3px;"&gt;
&lt;svg class="clip-svg absolute"&gt;
&lt;defs&gt;
&lt;clipPath id="swipe__clip-path" clipPathUnits="objectBoundingBox"&gt;
&lt;polygon points="0.5745 0, 0.5 0.33, 0.42 0, 0 0, 0 1, 0.27 1, 0.27 0.59, 0.37 1, 0.634 1, 0.736 0.59, 0.736 1, 1 1, 1 0, 0.5745 0" /&gt;
&lt;/clipPath&gt;
&lt;/defs&gt;	
&lt;/svg&gt;
&lt;/div&gt;
&lt;/div&gt;



---
# Background 

&lt;br&gt;


.grid[

&lt;div style="font-size:18pt"&gt;
&lt;h2&gt;Health threats&lt;/h2&gt;
&lt;p&gt;
&lt;b style="font-size:24pt"&gt;Life impacts (till April 2022)&lt;/b&gt;&lt;br&gt;
6.07 million people infected and 7355 people have died. There are many short-term and long-term adverse effects on people who get covid-19. &lt;br&gt;
&lt;br&gt;
&lt;b style="font-size:24pt"&gt;Economic impacts&lt;/b&gt;&lt;br&gt;
Australia has lost billions of money because of the pandemic. In 2020, 72% of businesses generated much lower revenue than before. Moreover, the job losses have reached 1.6 million jobs lost in two weeks after the global pandemic was announced. The underemployment rate hit historically high with 13.8% by the end of April, 2020. 
&lt;/p&gt;
&lt;/div&gt;

&lt;img src="images/covid.png" alt="Trulli" style="width:60%;height:auto"&gt;
&lt;img src="images/covid2.png" alt="Trulli" style="width:53%;height:auto"&gt;
&lt;img src="images/covid3.png" alt="Trulli" style="width:40%;height:auto"&gt;
]


---
# Research Aim 

__The overall research aim is to evaluate the employment effects of COVID-19 via developing a model for the two-digit subsectors (&lt;u&gt;86 totally&lt;/u&gt;) .  __ 

&lt;small style="font-size:14pt"&gt; I'm also trying to solve the following tasks: &lt;/small&gt;



+ To construct a time series multivariate model of employment in 86 subsectors of the Australian economy. 

--

+ To use this model to conduct a counterfactual analysis 

--

+ To use this model to determine which sectors have the highest impact (or positive spillover) on employment growth. 


---
# Review of Literature 
# Sectoral studies of COVID-19:



.font_my_2[

+ At a worldwide level, International Labor Organisation provided some initial estimates and concluded the "Accommodation &amp; Food services", "Real Estate, Business,&amp; Administrative Activities", "Manufacturing", and "Wholesale &amp; Retail Trade" as high risk sectors. 
 

+ In US, &lt;small style="font-size:13pt"&gt;Ludvigson,Ma, and Ng (2020)&lt;/small&gt; developed a costly disaster model to translate the impacts of deadly disasters in recent US history and modeled as shocks to predict the COVID-19 influences.  &lt;small style="font-size:13pt"&gt;Gregory, Menzio, and Wiczer (2020)&lt;/small&gt; expand some Model-based analysis of the disaggregate impacts of 20 sectors. 


+ In France, &lt;small style="font-size:13pt"&gt;Barrot, Grassi and Sauvagnat (2020)&lt;/small&gt; estimated the impacts at sectoral level. They then use a production network model to estimate the drop of total GDP and sectoral performances. 


]

--
### Limitation:

However, not many studies have done in Australia (as a small open economy nothing like US, Europe).




---
# Review of Literature

&lt;br&gt;

&lt;br&gt;

.grid[
.font_my_2[

### An Aussie story begins:
+ Anderson et al. (2020) conducted a multivariate time series Bayesian VARX model for 19  broad sectors in Australia. Their research conducted in 2020 at the time full of uncertainty. Therefore, they applied an "conditional forecasting" method to simulate different scenarios for the sectoral employment in Australia during the pandemic. 



### Limitation:

Some useful information about macroeconomic analysis may lose due to the differences in 19 (broad level) sectors and 86 (Two-digit level) sectors. 


]

.font_my_2[

&lt;img src="figure/pyramid.png" style="width: 110%; float:right"/&gt;

]

]


---

# Exploratory Data Analysis


+ **Don't judge them by their appearances**


&lt;small style="font-size:13pt"&gt;Here is the reason why we expand Anderson et al. (2020) to a two-digit level. See the differences :-) &lt;/small&gt; &lt;small style="font-size:13pt"&gt;If we stimulate a industry at a broad sector level, our policy may **lack of efficiency**. &lt;/small&gt;


&lt;br&gt;

.grid[

&lt;img src="figure/manu19.png" style="width: 90%; float:left"/&gt;

&lt;img src="figure/manu87.png" style="width: 90%; float:right"/&gt;


]


&lt;br&gt;



---
# Project Design (Data)

## Data Sources: 

&lt;br&gt;

.font_my_2[

+ Number of Employment by Industry at subdivision (i.e. subsector) level: Retrived from [ABS Labour Force, Australia, Detailed](https://www.abs.gov.au/statistics/labour/employment-and-unemployment/labour-force-australia-detailed/latest-release)

]



&lt;br&gt;

## Supplementary Data 

&lt;br&gt;

.font_my[

+ **Total Labour Force**: Australian Bureau of Statistics ABS(2022a)

+ **Unemployment Rate**: Australian Bureau of Statistics ABS(2022b)

]


---
#Project Design (Data)

## Data Wrangling 

&lt;br&gt;

.font_my[

①: Some small or new subsectors(e.g. Internet Publishing) have no historical records of employment, we combine them with similar sectors that are "non-zero".]

--

&lt;br&gt;


.font_my[

②: An **logarithm** and a **seasonal difference ** will be conducted to eliminate the seasonality and make it **stationary**, which will make it easier to conduct further steps. 

]





---
# Project Design (Data)


&lt;br&gt;

+ **Why don't I use the seasonally adjusted data ?**
--
.font_my_2[

+ Seasonally adjusted sectoral data in ABS do not add up seasonally adjusted total employment. Due to the seasonality of post-COVID data have changed. I CANNOT make reliable evaluation !!! 

+ All new changes are expressed in terms of the raw figures.  
]

--

&lt;br&gt;


+ **What about the non-classified Data?**

--
.font_my_2[

+ We found there is no further direction to classify the data. Therefore, to make sure the individual dynamics are consistent, we will not consider them in our research. 


]





---

# Project Design (Modelling)

+ **Vector Autoregression** with **Exogenous Variable** Model (VARX) is a useful model to estimate the dynamic behaviors of the relationship between variables in a statistically coherent way. &lt;small style="font-size:14pt"&gt;(Anderson et al.,2020;Litterman, 1986;Bańbura,Giannone,&amp;Reichlin,2010)&lt;/small&gt;


`$$\textbf{y}_t=\textbf{c}+\textbf{A}_1 \textbf{y}_{t-1}+\bf{\Gamma}\textbf{x}_{t-1}+\bf{u}_t$$`
.font_small[
**where:**  
]


.font_my_2[

+ `\(\bf{y}_t\)` is an `\(84\times1\)` vector of two-digit subsectoral employment growth rate at time `\(t\)` with `\(\bf{A}_{1}\)` are `\(84\times84\)` parameter matrices. There are one lag of growth rate due to the high dimensionality and small sample size. 

+ `\(x_{t-1}\)` is a scalar of one lag of the growth rate of total employment with `\(\bf{\Gamma}\)` is `\(84\times1\)` parameter matrices, which act as economy-wide factors. 

+ Reduced form errors `\(\bf{u}_t \sim N(0,\bf{\Sigma})\)`. 

]


---
class:center
# Project Design (Modelling)
##Bayesian Inference in VARX modelling

.font_my_2[
+ We have 7224 parameter to estimate (frequentist is not suitable). `\(\bf{\beta}\)` contains `\(\bf{c}\)`, `\(\bf{A_1}\)` and `\(\bf{\Gamma_1}\)`

+ **Bayesian inference** derives the posterior probability as a consequence of two antecedents: a *Prior Probability* and a *Likelihood Function* derived based on the observed data.]

&lt;br&gt;

--

.font_my_2[
+ We can think of Bayesian Estimation as `\(Posterior = Likelihood\times Prior\)` ]

`$$f(\bf{\beta}|y)\propto L(\beta|y)f(\beta)$$`
.font_small[
`\(f(\bf{\beta})\)` = the **prior** pdf for `\(\bf{\beta}\)`;expresses prior uncertainty about the `\(\beta\)`

`\(f(\bf{\beta}|y)\)` = the **posterior** pdf of `\(\bf{\beta}\)`; expresses uncertainty about `\(\beta\)` **after** having observed the data `\(\bf{y}\)` (or **conditional** on the observed data)
]

.font_my[

+ We can bring our beliefs (priors) to the parameter. After seeing the data (likelihood), we get the posterior by combining the likelihood and the prior together.

]




---
# Project Design (Prior Selection)

.font_my[
&lt;b&gt;Aim&lt;/b&gt;: We use Minnesota prior to shrink the unrestricted model towards a random walk, thereby reducing the parameter uncertainty and improving forecast accuracy. &lt;small style="font-size:11pt"&gt;(Anderson et al.,2020;Litterman,    1986;Bańbura,Giannone,&amp;Reichlin,2010;Karlsson,2013)&lt;/small&gt;  

]


.font_my[

&lt;br&gt;

&lt;b&gt;Benefits&lt;/b&gt;:  
 
  a. Eliminate &lt;u&gt;high-dimensionality&lt;/u&gt; curse. 
  
  b.  It makes the most &lt;u&gt;recent lag&lt;/u&gt; provide more information than distant lags. 
  
  c. It makes &lt;u&gt;own lags&lt;/u&gt; explain more than the lags of other variables.
  
]

&lt;br&gt;
  
.font_my_2[
&lt;b&gt;Apply&lt;/b&gt; : I will apply it in the BVAR system by creating a **Normal- Inverse-Wishart prior** (which *retain the principal of Minnesota prior*) and then adding dummy observations to put the posterior moments of Normal IW prior inside our BVAR system. &lt;small style="font-size:11pt"&gt;(Bańbura,Giannone, and Reichlin (2010))&lt;/small&gt; 

]

---

# Project Design (Details)

&lt;b&gt;Mean&lt;/b&gt;:

--
.font_my_2[
 `$$E[a_{1}^{jk}] = E[\gamma_{1}^j]=0$$`

] 

--


**Variances**:

--
.font_my_2[
 For the lag of growth rate:

`$$Var[a_1^{jk}]=\lambda^2,j=k$$`




`$$Var[a_1^{jk}]= \frac{\lambda^2\sigma^2_j}{\sigma^2_k}, otherwise$$`

 
 For the lag of total employment:

`$$Var[\gamma_1^{j}]=\frac{\lambda^2\sigma^2_j}{\sigma^2_e}$$`
]




.font_small[

&lt;u&gt;&lt;b&gt;Note&lt;/b&gt;&lt;/u&gt;: `\(\lambda\)` control the overall tightness(variance of prior distribution) and governs the relative importance of the prior beliefs *w.r.t* the information contained in the data;  `\(\frac{\sigma_j}{\sigma_k}\)` adjusts for different scale and variability. 


]


 &lt;!-- If `\(\lambda\rightarrow0\)`, we can see that the prior assumption is influential, which means that the posterior getting closer to the prior, so the data have no influence on the estimates. On the contrary, if `\(\lambda\rightarrow\infty\)`, the posterior expectations will approach to ordinary least squares (OLS) estimates. In many macroeconomic VAR forecasting, data are presented in a large dimension. As the dimension increases, we want to shrink more in order to avoid the over-fitting [@de2008] --&gt;



---
# Selection of hyperparameter `\(\lambda\)`
# A new approach in selecting hyperparameter `\(\lambda\)`

.font_my_2[

+ Conventional error measurements (e.g. MAE, MSE or MAPE) are no longer robust when sizes of subsectors are small with various scales. 

]

.font_my_2[

+ We minimising a new error measurement "Root Mean Squared Forecast Error" via an out-of-sample forecasting experiment algorithm. ]


`$$RMSFE^{\lambda}_{i}=\sqrt{\frac{1}{T_e-T_b-1}\Sigma^{T_{e}-1}_{T=T_{b}}({y}_{i,T+1|T}^{\lambda}-y_{i,T+1})^2}$$`

&lt;br&gt;

.font_small[ 

+ where `\({y}_{i,T+1|T}^{\lambda}\)` is defined as the `\(1\)`-th steps ahead forecast given the information up to time `\(T\)` and `\(y_{i,T+1}\)` is the actual data for the `\(1\)`-th steps ahead forecast. Here, `\(\lambda\)` stands for the evaluated RMSFE, conditioned on the hyperparameter `\(\lambda\)`. 

]




---
class:center
# Selection of hyperparameter `\(\lambda\)`
# Diagram of the grid search

&lt;br&gt;

&lt;img src="figure/flowalgo.png" style="width:100%"&gt;

&lt;br&gt;
.font_my_2[

+ From 3000 different combinations `\(\lambda\)` from 0.0001 to 0.3, we found the `\(\lambda=0.0808\)` has the lowest RMFSE. 


] 

---
# Empirical Results (Sectoral Multiplier Analysis)


.grid[

.font_my_2[

&lt;br&gt;


#### Background

The total employment growth is: 

`$$GR_T=\sum_{j=1}^{84} w_j\times {GR}_j$$`

&lt;small style="font-size:12pt"&gt;(where `\(w_j\)` is the share of employment of two-digit sector `\(j\)` in the total employment and  `\(GR_j\)`  is the growth rate in employment of two-digit sector j and  `\(GR_T\)`  is the growth rate in total employment )&lt;/small&gt;

📈 Due to the interconnection of macroeconomic two-digit subsectors, when a two-digit subsector `\(j\)` has an increase in employment, in the long run, it may have spillover effect onto other two-digit subsectors, especially those that have high connections with the two-digit subsector `\(j\)`. 

]



.font_my_2[

&lt;br&gt;

&lt;br&gt;

&lt;ul&gt;&lt;b&gt;Why is it useful?&lt;/b&gt;&lt;/ul&gt;

+ This will take the &lt;u&gt;structure of industries&lt;/u&gt; into consideration, which is more closer to the reality. It also allows us to assess the damage of COVID-19 to these industries.  

+ This will help us to evaluate the efficiency of policies. For example, if policies simulate these subsectors, there will be a *bonus* and then we can say &lt;u&gt;"a dollar to these high spillover industries is more valuable than a dollar"&lt;/u&gt;

]
]




---
# Empirical Results (Sectoral Multiplier Analysis)
## Long run employment multipliers


&lt;img src="figure/top10.png" width="100%" style="display: block; margin: auto;" /&gt;


.font_my_2[ 
+ 10 subsectors generate strongest positive spillovers (right) and biggest negative spillovers (left).

]


 
 
---
# Empirical Results (Evaluation after COVID-19)
## Losses of total employment after COVID-19


&lt;img src="figure/cont_analysis.png" width="85%" style="display: block; margin: auto;" /&gt;

--
.font_my_2[

+ Huge losses of employment compare with the no-COVID scenario.

+ The trend is essentially parallel with the exception of 2021 Q2 to Q4 (growth rate recovered). 

]


---
# Empirical Results (Evaluation after COVID-19)
## Changes of year-on-year growth rate




&lt;img src="figure/yoy1.png" width="60%" style="display: block; margin: auto;" /&gt;

--

.font_my_2[

+ The year-on-year growth gradually recovered after the shock. 

+ The impact of COVID-19 cannot recover in a short-term (unless there is a higher year-on-year growth in the future.) 

]



---
# Empirical Results (Unemployment Rate)


.grid[

.font_my_2[

&lt;br&gt;


&lt;ul&gt;&lt;b&gt;Historically Lowest Unemployment:&lt;/b&gt;&lt;/ul&gt;

Australia has recorded the lowest unemployment level in 48 years. What is the underlying of this when &lt;b&gt;I&lt;/b&gt; said we have not recovered yet? 


`$$U_{emp}=\frac{T_L-T_E}{T_L}$$`
.font_small[
where `\(U_{emp}\)` is the unemployment rate; `\(T_L\)` is the total labour force; `\(T_E\)` total employed people.
]

&lt;ul&gt;&lt;b&gt;Drives of low unemployment rate:&lt;/b&gt;&lt;/ul&gt; 

+ Lower labour force. 

+ Higher Employed People. 


]
.font_my_2[

&lt;br&gt;

&lt;img src="figure/unemp1.png" style="width:70%"&gt;
&lt;img src="figure/unemp2.png" style="width:70%"&gt;

]

]





---
# Empirical Results (Unemployment Rate)




&lt;img src="figure/con_labourf.png" width="90%" style="display: block; margin: auto;" /&gt;

.font_small[Note: The forecasts of total labour force are generated via `ARIMA` function in package `fpp3 0.4.0` by Rob Hyndman]


.font_my_2[

+ We see that the total labour force has declined significantly compare with no-COVID case. 

+ The lowest unemployment rate is mainly driven by the decline of **total labour force**. 


]


---
# Empirical Results (Unemployment Rate)


&lt;img src="figure/con_rate.png" width="80%" style="display: block; margin: auto;" /&gt;

.font_my_2[

1. The finding suggests the low unemployment rate would achieve lowest even without the COVID. 

2. The stimulus policies during the COVID do not contribute the most for the low unemployment rate. 

&lt;!-- if u think it's government stimulate the economy during covid is wrong  --&gt;



]



---
# Discussions⌕

**Policy Implications**

&lt;br&gt;

.font_my[

📈 More appropriate policies should stimulate those high-spillover subsectors in a disaggregated level if government want to increase the number of employment more effeciently. 

&lt;br&gt;

👷The COVID-19 has affected the total employment and the labour force participation. Policies should focus on both employment and total labour force at this stage.
 
&lt;br&gt;
📉 Government should be aware that relatively low unemployment rate may reflect the labour shortage (E.g. Reforming the immigration system or issuing more WHV to attract more labour overseas).

]
---

# Discussions⌕
## Summary



+  Bayesian VAR model is used to estimate the no-COVID scenario.

&lt;br&gt;

--
+  Algorithm to select the best hyperparameter for the Minnesota prior  applied in the proposed BVAR.

&lt;br&gt;

--
+  Simulate the disaggregated subsectoral spillovers via impulse responses. 

&lt;br&gt;

--
+  A complete evaluation of both the impacts of COVID-19 and discover the underlying reason of low unemployment rate after the COVID-19. 






---
# Extensions

&lt;br&gt;

🤖 To improve the forecast accuracy, machine learning algorithms or combination forecasts can be considered for accurate and interpretable forecasts. 

&lt;br&gt;
--

👨‍💻 To make our analysis more broad and easily accessible by researchers or government. An interactive shiny application can be implemented to give a more accessible way and thus benefit more people.

&lt;br&gt;
--

♾ Bring more hierarchies to our analysis and make forecasts coherent using the hierarchical forecasting methods. 


&lt;br&gt;
---
class: center
# 👨‍🏫 SPECIAL 👨‍💻 THANKS 👩‍🏫
&lt;br&gt;

&lt;br&gt;



.monash-blue[I would like to gratitude my supervisor, 

**Farshid Vahid**, for your patient and selfless guidance.]

&lt;br&gt;

.monash-blue[I would also appreciate **Heather Anderson** for your devoted care along the journey.]

&lt;br&gt;

.monash-blue[Special thanks to  **Benjamin Wong** for offering kind supports and the MATLAB packages.]



---
&lt;b&gt;Figure Source&lt;/b&gt;
.font_small[

covid image1: https://humanrights.gov.au/our-work/childrens-rights/publications/impacts-covid-19-children-and-young-people-who-contact-kids

covid image2: https://aurin.org.au/covid-and-employment/

covid image3: https://www.forbes.com/sites/advisor/2020/04/14/coronavirus-concerns-will-less-income-or-job-loss-hurt-your-credit-score/?sh=648c744e4dc4

Front page Data Source: The first year of COVID-19 in Australia: direct and indirect health effects, Summary - Australian Institute of Health and Welfare. (2022). Retrieved 8 May 2022, from https://www.aihw.gov.au/reports/burden-of-disease/the-first-year-of-covid-19-in-australia/summary

fence:https://canberraweekly.com.au/best-fencing-contractors/

window maker: https://www.bizjournals.com/tampabay/news/2020/02/05/pgt-completes-92m-acquisition-of-tampa-based-door.html

Unemplyment: Marsh, S. (2022). Australia's unemployment rate plummets to lowest level in 48 years. Retrieved 2 October 2022, from https://www.9news.com.au/national/australia-unemployment-rate-july-2022-lowest-rate-since-august-1974/d16e2bac-c9f1-435f-ad25-cb2964d292f0 





]

&lt;b&gt;Major references&lt;/b&gt;

.font_small[

ABS. (2021). One year of covid-19: Aussie jobs, business and the economy. Retrieved April 29, 2022, from https://www.abs.gov.au/articles/one-year-covid-19-aussie-jobs-business- and-economy

Anderson, H, Caggiano, G, Vahid, F, &amp; Wong, B. (2020). Sectoral employment dynamics in australia and the covid-19 pandemic. Australian Economic Review, 53(3), 402–414.


Bańbura, M, Giannone, D, &amp; Reichlin, L. (2010). Large bayesian vector auto regressions. Journal of applied Econometrics, 25(1), 71–92.


International Labour Organization 2020. ILO Monitor: Covid‐19 and the World of Work.

Karlsson, S. (2013). Forecasting with Bayesian vector autoregression. Handbook of economic forecasting, 2, 791-897.

Kadiyala, KR, &amp; Karlsson, S. (1997). Numerical methods for estimation and inference in bayesian var-models. Journal of Applied Econometrics, 12(2), 99–132.

Litterman, RB. (1986). Forecasting with bayesian vector autoregressions—five years of experience.Journal of Business &amp; Economic Statistics, 4(1), 25–38.

]
---




background-image: url(images/auz_workers.jpeg)
background-size: cover
class: hide-slide-number split-70
count: false

.column.shade_black[.content[

&lt;br&gt;&lt;br&gt;

## Acknowledgements

Slides produced using [Rmarkdown](https://github.com/rstudio/rmarkdown) with [xaringan](https://github.com/yihui/xaringan) styling. 


&lt;br&gt; 


&lt;br /&gt;
This work is licensed under a &lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License&lt;/a&gt;.

&lt;a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;&lt;img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /&gt;&lt;/a&gt;


##Thanks for Listening
## Any Questions?

.bottom_abs.width100[

Author: Zhixiang Yang (Elvis)

Department of Econometrics and Business Statistics&lt;br&gt;
<span>&lt;i class="fas  fa-envelope faa-float animated "&gt;&lt;/i&gt;</span>  zyan0056@student.monash.edu

]


]]



&lt;div class="column transition monash-m-new delay-1s" style="clip-path:url(#swipe__clip-path);"&gt;
&lt;div class="background-image" style="background-image:url('images/large.png');background-position: center;background-size:cover;margin-left:3px;"&gt;
&lt;svg class="clip-svg absolute"&gt;
&lt;defs&gt;
&lt;clipPath id="swipe__clip-path" clipPathUnits="objectBoundingBox"&gt;
&lt;polygon points="0.5745 0, 0.5 0.33, 0.42 0, 0 0, 0 1, 0.27 1, 0.27 0.59, 0.37 1, 0.634 1, 0.736 0.59, 0.736 1, 1 1, 1 0, 0.5745 0" /&gt;
&lt;/clipPath&gt;
&lt;/defs&gt;	
&lt;/svg&gt;
&lt;/div&gt;
&lt;/div&gt;



---
class: center
#APPENDIX (Bayesian VAR)

.font_my_2[

`$$\begin{align}
\textbf{y}_t&amp;=\textbf{c}+\textbf{A}_1 \textbf{y}_{t-1}+\bf{\Gamma}_1\textbf{x}_{t-1}+\bf{u}_t\\
&amp;=
\begin{bmatrix}
c_1\\
\vdots\\
c_n
\end{bmatrix}
+
\begin{bmatrix}
a_1^{11}&amp;\cdots&amp;a_1^{1n}&amp;\gamma_1^{1}\\
\vdots&amp;\ddots&amp;\vdots&amp;\vdots\\
a_1^{n1}&amp;\cdots&amp;a_1^{nn}&amp;\gamma_1^n&amp;\\
\end{bmatrix}
\begin{bmatrix}
\bf{y}_{t-1}\\
x_{t-1}\\
\end{bmatrix}\\
&amp;+
\begin{bmatrix}
u_{1,t}\\
\vdots\\
u_{n,t}
\end{bmatrix}\\
\end{align}$$`
]

.font_my_2[
+ where `\(E(\bf{u}_t\bf{u}'_t)=\bf{\Sigma}\)` and `\(E(\bf{u}_t\bf{u'}_{t-1})=0\)`. The `\(n\)` represent the number of sectors (or in our case will be 84) and `\(c\)` represents the vector of constants. There are one lag (p=1) included for the total employment `\((x_{t-1})\)` as predetermined variable at time `\(t\)`.

]
---
# Appendix (Minnesota Prior)

.font_my_2[
`$$\begin{aligned}\label{eq:1}
&amp;E[a_{j}^{jk}] = E[\gamma_{i}^j]=0\\
\\
&amp;Var[a_j^{jk}]= 
\begin{cases}
\frac{\lambda^2}{i^2},&amp;j=k\\
\frac{\lambda^2}{i^2}\frac{\sigma^2_{j}}{\sigma^2_k},&amp; otherwise
\end{cases}\\
\\
&amp;Var[\gamma_i^{j}]=\frac{\lambda^2}{i^2}\frac{\sigma^2_{j}}{\sigma^2_e}
\end{aligned}$$`
]

.font_my_2[

+ The degree of shrinkage is governed by `\(\lambda\)`, `\(\frac{1}{i^2}\)` to down-weight more distant lags and the `\(\frac{\sigma_j^2}{\sigma_k^2}\)` adjusts for different scale of the data. `\(\sigma^2_e\)` is the variance after fitting an AR model on total employment growth. 

]


---
# Our system 
.font_my_2[
`$$\begin{aligned}\underbrace{Y}_{T\times n} = \underbrace{XB}_{T\times k \times k \times n} \ +\underbrace{U}_{T\times n}\end{aligned}$$`

where `\(\bf{Y}=(Y_1,\cdots,Y_T)'\)`;and `\(\bf{X}=(X_1,\cdots,X_T)'\)` with `\(X_t=(Y'_{t-1},x_{t-1},1)'\)` and `\(u=(u_1,\cdots,u_T')\)` . 

]

**Normal-Inverse-Wishart Prior** 

.font_my_2[
The Normal-Inverse-Wishart Prior has the form 

`$$\begin{aligned}
&amp;\bf{vec(\mathbf{B})}|\bf{\Sigma}\sim N(\bf{vec}(\bf{B_0}),\Sigma\otimes\Omega_0)\ \\
&amp;\bf{\Sigma}\sim\mathbf{IW}(\bf{S_0},a_0)\end{aligned}$$`

where the prior parameters `\(\mathbf{\beta}_0\)` and `\(\bf{\Omega_0}\)`, `\(\bf{S_0}\)`  and `\(a_0\)` such that they are consistent with the Minnesota prior we mentioned before and the expectation of `\(\bf{\Sigma}\)` being `\(diag(\sigma_1^2,\cdots,\sigma_n^2)\)`.
]
---
# Normal-Inverse-Wishart Prior (Set Up Dummies)

.font_my_2[
`$$\begin{aligned}
\bf{Y_d}&amp;=
\begin{pmatrix}
\bf0_{np+p,n}\\
\bf diag(\bf{\sigma_1,\cdots,\sigma_n})\\
\bf0_{1\times n}
\end{pmatrix}\\
\end{aligned}$$`


`$$\begin{aligned}
\bf{X_d}&amp;=
\begin{pmatrix}
\bf{J_p}\otimes diag(\frac{\sigma_1}{\lambda}\cdots\frac{\sigma_n}{\lambda},\frac{\sigma_e}{\lambda})&amp;\bf0_{(np+p)\times1}\\
\bf 0_{n,np+p}&amp;\bf 0_{n\times1}
\\
\bf 0_{1,np+p}&amp;\bf \epsilon
\end{pmatrix}
\end{aligned}$$`

]

.font_my_2[


&lt;br&gt;


where:
`\(\bf{J_p}=diag(1,\cdots,p)\)`; `\(\bf{S_0}=(Y_d-X_d\times B_0)'(Y_d-X_dB_0)\)`, `\(\bf{B_0}=(X_d'X_d)^{-1}X_dY_d\)`, `\(\bf{\Omega_0}=(X_d'X_d)^{-1}\)` and  `\(a_0=T_d-np-p-1\)`; `\(\epsilon\)` is a small number to impose an uniformative and diffused prior on the constants. 



&lt;br&gt;

Here, both `\(\bf{Y}_d\)` and `\(\bf{X}_d\)` are the dummy observations we set 
where `\(T_d\)` is the number of rows for both `\(\bf{Y}_d\)` and `\(\bf{X}_d\)`.
]

---
# Normal-Inverse-Wishart Prior 


## We can get:

.font_my[

`$$\begin{aligned}
\bf{Y^*}=\bf{X^*}\bf{B}+\bf{\mu}^*\\
\end{aligned}$$`

where : 


`$$\begin{aligned}
\bf{Y^*}=[\bf{Y'},\bf{Y'_d}]';\ \bf{X^*}=[\bf{X'},\bf{X'_d}]';\ \bf{\mu^*}=[\bf{\mu'},\bf{\mu'_d}]'
\end{aligned}$$`

]

.font_my_2[
Then we can estimate the BVAR by conducting an least square regression of `\(Y^*\)` on `\(X^*\)` . The posterior distribution then have the form of

`$$\begin{align}
&amp;\bf{vec(\mathbf{B})}|\Sigma,Y\sim N(vec(\bf{\tilde{B}}),\Sigma\otimes(\bf{X^*}'\bf{X^*})^{-1})\ and\\
&amp;\bf{\Sigma|Y}\sim\mathbf{IW}(\bf{\tilde\Sigma},T_d+T-np+2)
\end{align}$$`


where `\(\bf{\tilde{B}} =(X*'X*)^{-1}X^{*'}Y^*\)` and `\(\bf{\tilde\Sigma}=(\bf{Y^*}-\bf{X^*}\bf{\tilde{B}})'(\bf{Y^*}-\bf{X^*}\bf{\tilde{B}})\)`

]


---
# Further Details 

.font_small[
Groups of 42 Other Store-Based Retailing

421 Furniture, Floor Coverings, Houseware and Textile Goods Retailing

422 Electrical and Electronic Goods Retailing

423 Hardware, Building and Garden Supplies Retailing

424 Recreational Goods Retailing

425 Clothing, Footwear and Personal Accessory Retailing

426 Department Stores

427 Pharmaceutical and Other Store-Based Retailing

] 

.font_small[

Groups of 72 Administrative Services


721 Employment Services

722 Travel Agency and Tour Arrangement Services

729 Other Administrative Services


]

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLanguage": "r",
"highlightLines": true,
"highlightSpans": false,
"countIncrementalSlides": false,
"slideNumberFormat": "%current%/%total%",
"navigation": {
"scroll": false,
"touch": true,
"click": false
},
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'assets/mathjax-local/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
