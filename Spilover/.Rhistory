geom_line(aes(x = Date, y = fgr1), colour = "Blue") +
ylab("YoY Growth in Total Employment in %") +
scale_x_yearqtr(format = "%YQ%q", breaks = seq(as.yearqtr(2020.25),as.yearqtr(2022.25), by = 0.5), minor_breaks= seq(as.yearqtr(2020.25),as.yearqtr(2022.25), by = 0.25))+
labs(title = "Counterfactual Analysis of Year on Year Growth Rate", subtitle = "Red: Optimistic Scenario; Blue: Actual ")
grow1
#write.csv(file = "oneemp.csv",allrawfcasts)
grow2 <- ggplot(allrawfcasts,aes(x=Date, y=YoY)) +
geom_line(aes(x = Date, y = YoY), colour = "Red") +
ylab("YoY Growth in Total Employment in %") +
scale_x_yearqtr(format = "%YQ%q", breaks = seq(as.yearqtr(2020.25),as.yearqtr(2025.0), by = 0.5), minor_breaks= seq(as.yearqtr(2020.25),as.yearqtr(2025.0), by = 0.25))+
labs(title = "Forecast Values of Year-on-Year Growth Rate", subtitle = "Total Employment Based on the Optimistic Scenario")
grow1
grow2
# Compare the difference between the actual data and forecasts
comp_fore <- cbind(allrawfcasts[1:9,],  actual_covid[,ncol(actual_covid)])
## BOOTSTRAP
# Confidence Interval via Bootstrap based on empirical residuals
nboot = 1000
bootstraped_list = matrix(0,20,1000)
confidence_interval = matrix(0,20,2)
resid = d4logdata[-1,] - yhat[-1,]
fraw_boot = matrix(0,26,k)
fraw_boot[1:5,]= rawdata[(nrow(rawdata)-4):nrow(rawdata),]
fgr_boot = matrix(0,26,k)
fgr_boot[1,] = d4logdata[nrow(d4logdata),]
# Conduct the bootstrap via empirical residual
for (bb in 1:20){
for (b in 1:nboot){
for (i in 2:21){
for (j in 1:(k-1)){
fgr_boot[i,j]= phi[1,j] + fgr_boot[(i-1),]%*%phi[(2:86),j] + sample(resid, size = 1)
}
fraw_boot[i+4,1:(k-1)] = fraw_boot[i,1:(k-1)]*exp(fgr_boot[i,1:(k-1)]/100)
fraw_boot[i+4,k] = sum(fraw_boot[i+4,1:(k-1)])
fgr_boot[i,k]=100*log(fraw_boot[i+4,k]/fraw_boot[i,k])
}
bootstraped_list[,b] = as.numeric(fraw_boot[6:25,85])
}
confidence_interval[bb,] = as.numeric(quantile(bootstraped_list[bb,], prob = c(0.2,0.8)))
}
# Then we can plot the confidence interval respect to the actual forecasts
CI_80 <- data.frame("lower_bound" = confidence_interval[,1],"upper_bound" = confidence_interval[,2])
comp_fore <- cbind(CI_80[1:9,], comp_fore)
# The forecast number of total employment via Actual data, with 95 CI generated via bootstrap $
#write.csv(file ="oneemp.csv", comp_fore)
con <- ggplot(comp_fore,aes(x=Date, y=Employment)) +
geom_line(aes(x = Date, y = Employment), colour = "Blue") +
geom_line(aes(x = Date, y = `96 Total`)) +
geom_line(aes(x = Date, y = `lower_bound`),colour = "Red", linetype = "dashed") +
geom_line(aes(x = Date, y = `upper_bound`),colour = "Red", linetype = "dashed") +
labs(title = "Counterfactual Analysis of Total Employment", subtitle = "80% CI via Bootstrap with Empirical Residuals") +
ylab("Total Employment") + scale_x_yearqtr(format = "%YQ%q", breaks = seq(as.yearqtr(2020.25),as.yearqtr(2025.0), by = 0.5), minor_breaks= seq(as.yearqtr(2020.25),as.yearqtr(2025.0), by = 0.25))
con
comp_fore_val <- comp_fore |>
mutate(dd_origin = as.yearqtr(Date), Estimated = Employment, `X96.Total` = `96 Total`) |>
select(-`Date`, -`YoY`, - `Employment`, -`96 Total`,-`lower_bound`, -`upper_bound`)
estim_fore <- rbind(origin_fore,comp_fore_val)
fits <- estim_fore |>
ggplot(aes(x = dd_origin, y = Estimated))+ geom_line(colour = "Blue") + geom_line(aes(y =`X96.Total`),colour = "Red",linetype = "dashed") +
labs(x = "Quarter", y = "Employment in ('000)", title = "Fitness of the proposed VAR Modelling", subtitle = "Red line is Actual Data;Blue line is the Estimated Data ")
ggarrange(fits,con,nrow = 1, ncol = 2)
library(matrixStats)
library(ggplot2)
library(zoo)
library(tidyverse)
library(dplyr)
library(stats)
library(readr)
library(pracma)
library(lubridate)
library(fpp3)
library(ggpubr)
# generate the circular plots
library(viridis)
library(lessR)
alldata_init <- readr::read_csv("ABSemp.csv")  |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date, -`96 Total`)
alldata <- alldata_init|>
filter(Quarter <= yearquarter("2020 Q1")) |>
select(-Quarter)
# generate the total number
alldata <- alldata |>
mutate(`96 Total` = rowSums(alldata[,1:ncol(alldata)]))
# generate the total amount of the data
rawdata <- as.matrix(alldata) # Remove the NA values due to the loading of the data.
logdata <- log(rawdata)
d4logdata <- 100*(logdata[5:nrow(logdata),]-logdata[1:(nrow(logdata)-4),]) %>% as.matrix()
summary(d4logdata)  # check summary to see if data are read correctly
N=dim(d4logdata)[2]
p=4
phi <- read.csv("phi_lambda_00808.csv",header=FALSE) %>% as.matrix #estimated parameters produced by MATLAB code
n = nrow(d4logdata)
k = ncol(d4logdata)
rawhat = matrix(0,n+4,k)
yhat = matrix(0,n,k)
sdiff = matrix(0,n+4,k)
for (i in 2:n){
for (j in 1:(k-1)){
yhat[i,j]= phi[1,j] + t(d4logdata[(i-1),]) %*% phi[2:86,j]
}
rawhatv = rawdata[i,1:(k-1)] * exp(yhat[i,1:(k-1)]/100) # back transform
yhat[i,k]=100*log(sum(rawhatv)/rawdata[i,k])
rawhat[i+4,] = rawdata[i,1:k] * exp(yhat[i,1:k]/100)
sdiff[i+4,] = exp(yhat[i,1:k]/100)
}
test <- rawhat[-c(1:5),] - rawdata[-c(1:5),]
dd_origin = as.yearqtr(1986 + seq(0,136)/4)
#
origin_fore <- data.frame(dd_origin, "Estimated" = rawhat[-c(1:5),85] , `Actual`= as_tibble(alldata[-c(1:5),85]))
origin_fore |>
ggplot(aes(x = dd_origin, y = Estimated))+ geom_line(colour = "Blue") + geom_line(aes(y =`X96.Total`))
multiraw = matrix(0,44,k)
multiraw[1:4,]=rawdata[(nrow(rawdata)-3):nrow(rawdata),]
multig = matrix(0,44,k)
multilevels = matrix(0,44,k-1) # matrix that saves the evolution of total employment in reaction to 1 percent point shock in each sector
multigrowth = matrix(0,44,k-1) # matrix that saves the evolution of employment growth in reaction to 1 percentage point shock in each sector
for (sector in 1:(k-1)){
for (i in 5:44){
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
multiraw[i,1:(k-1)] = multiraw[(i-4),1:(k-1)] * exp(multig[i,1:(k-1)]/100) # The first value is negative means related to this
multiraw[i,k] = sum(multiraw[i,1:(k-1)])
multig[i,k]=100 * log(multiraw[i,k]/multiraw[(i-4),k])# Fourth difference and convert into percentage change  # PROBLEM: WHY LOG(1) \ne 0
}
multilevels[,sector]=multiraw[,k]
multigrowth[,sector]=multig[,k]   # suspect here will need to select k instead sector
}
multipliers = colSums(multigrowth)/4 # division by 4 is necessary because of seasonal differences
mpers = colCumsums(multigrowth[5:44,])/4 #colCumsums() is a function in matrixStats package
shares=colSums(rawdata[(nrow(rawdata)-3):nrow(rawdata),1:84])/sum(rawdata[(nrow(rawdata)-3):nrow(rawdata),85]) #sector shares estimated like this to eliminate the effect of seasonality
mtplers <- rbind(shares,mpers)
write.csv(file="multipliers_1.csv",rbind(shares,mpers))
View(mtplers)
??pivot_longer
mtplers |>
pivot_longer(names_to = "Sector")
mtplers |>
tibble()
mtpler_longer<- mtplers |>
tibble()
View(mtpler_longer)
mtpler_longer<- mtplers |>
tibble() |>
pivot_longer(names_to = "Sector")
mtpler_longer<- mtplers |>
tibble() |>
pivot_longer(everything(),names_to = "Sector")
View(mtpler_longer)
mtpler_longer<- mtplers |>
tibble()
View(mtpler_longer)
mtpler_longer<- mtplers |>
as.tibble()
View(mtpler_longer)
mtpler_longer<- mtplers |>
as.tibble() |>
pivot_longer(everything(),names_to = "Sector")
View(mtpler_longer)
source("~/Desktop/hon_proj/Disaggregated_Employment/Spilover/forecast_onelag.R", echo=TRUE)
# Elvis Yang
# June 2022
# This is the program computes the multipliers and contrafactural or scenario forecasting
library(matrixStats)
library(ggplot2)
library(zoo)
library(tidyverse)
library(dplyr)
library(stats)
library(readr)
library(pracma)
library(lubridate)
library(fpp3)
library(ggpubr)
# generate the circular plots
library(viridis)
# Donut plot
library(lessR)
# clean the data and reset the total employment by removing the NFD data
alldata_init <- readr::read_csv("ABSemp.csv")  |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date, -`96 Total`)
alldata <- alldata_init|>
filter(Quarter <= yearquarter("2020 Q1")) |>
select(-Quarter)
# generate the total number
alldata <- alldata |>
mutate(`96 Total` = rowSums(alldata[,1:ncol(alldata)]))
# generate the total amount of the data
rawdata <- as.matrix(alldata) # Remove the NA values due to the loading of the data.
logdata <- log(rawdata)
d4logdata <- 100*(logdata[5:nrow(logdata),]-logdata[1:(nrow(logdata)-4),]) %>% as.matrix()
summary(d4logdata)  # check summary to see if data are read correctly
N=dim(d4logdata)[2]
p=4
# generate the phi of your estimated model
phi <- read.csv("phi_lambda_00808.csv",header=FALSE) %>% as.matrix #estimated parameters produced by MATLAB code
n = nrow(d4logdata)
k = ncol(d4logdata)
# For users, you have to replace the numbers phi if you really want to build up another type of model
# The phi is produced using MATLAB MAIN.m file, please run that file to generate the estimated coefficients.
rawhat = matrix(0,n+4,k)
yhat = matrix(0,n,k)
sdiff = matrix(0,n+4,k)
for (i in 2:n){
for (j in 1:(k-1)){
yhat[i,j]= phi[1,j] + t(d4logdata[(i-1),]) %*% phi[2:86,j]
}
rawhatv = rawdata[i,1:(k-1)] * exp(yhat[i,1:(k-1)]/100) # back transform
yhat[i,k]=100*log(sum(rawhatv)/rawdata[i,k])
rawhat[i+4,] = rawdata[i,1:k] * exp(yhat[i,1:k]/100)
sdiff[i+4,] = exp(yhat[i,1:k]/100)
}
test <- rawhat[-c(1:5),] - rawdata[-c(1:5),]
dd_origin = as.yearqtr(1986 + seq(0,136)/4)
#
origin_fore <- data.frame(dd_origin, "Estimated" = rawhat[-c(1:5),85] , `Actual`= as_tibble(alldata[-c(1:5),85]))
# Compute the original data
origin_fore |>
ggplot(aes(x = dd_origin, y = Estimated))+ geom_line(colour = "Blue") + geom_line(aes(y =`X96.Total`))
# Conduct our multiplier analysis
# The row we set 44 is 4(4 last observations to start forecasting) + 40(10 years horizon of forecasting)
multiraw = matrix(0,44,k)
multiraw[1:4,]=rawdata[(nrow(rawdata)-3):nrow(rawdata),]
multig = matrix(0,44,k)
multilevels = matrix(0,44,k-1) # matrix that saves the evolution of total employment in reaction to 1 percent point shock in each sector
multigrowth = matrix(0,44,k-1) # matrix that saves the evolution of employment growth in reaction to 1 percentage point shock in each sector
for (sector in 1:(k-1)){
for (i in 5:44){
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
multiraw[i,1:(k-1)] = multiraw[(i-4),1:(k-1)] * exp(multig[i,1:(k-1)]/100) # The first value is negative means related to this
multiraw[i,k] = sum(multiraw[i,1:(k-1)])
multig[i,k]=100 * log(multiraw[i,k]/multiraw[(i-4),k])# Fourth difference and convert into percentage change  # PROBLEM: WHY LOG(1) \ne 0
}
multilevels[,sector]=multiraw[,k]
multigrowth[,sector]=multig[,k]   # suspect here will need to select k instead sector
}
multipliers = colSums(multigrowth)/4 # division by 4 is necessary because of seasonal differences
mpers = colCumsums(multigrowth[5:44,])/4 #colCumsums() is a function in matrixStats package
shares=colSums(rawdata[(nrow(rawdata)-3):nrow(rawdata),1:84])/sum(rawdata[(nrow(rawdata)-3):nrow(rawdata),85]) #sector shares estimated like this to eliminate the effect of seasonality
mtplers <- rbind(shares,mpers)
#write.csv(file="multipliers_1.csv",rbind(shares,mpers))
m5m0_div
m5m0_div <- mtplers[40,] / shares
m5m0_min <- (mtplers[40,] - shares)
m5m0_div
cbind(m5m0_div,m5m0_min)
test <- as.tibble(cbind(m5m0_div,m5m0_min))
View(test)
write.csv("spillover_effect.csv",cbind(m5m0_div,m5m0_min))
write.csv("spillover_effect.csv",cbind(m5m0_div,m5m0_min))
write.csv(file = "spillover_effect.csv",cbind(m5m0_div,m5m0_min))
# Average losses
rowSums(average_losses)
#
origin_fore <- data.frame(dd_origin, "Estimated" = rawhat[-c(1:5),85] , `Actual`= as_tibble(alldata[-c(1:5),85]))
# Elvis Yang
# June 2022
# This is the program computes the multipliers and contrafactural or scenario forecasting
library(matrixStats)
library(ggplot2)
library(zoo)
library(tidyverse)
library(dplyr)
library(stats)
library(readr)
library(pracma)
library(lubridate)
library(fpp3)
library(ggpubr)
# generate the circular plots
library(viridis)
# Donut plot
library(lessR)
# clean the data and reset the total employment by removing the NFD data
alldata_init <- readr::read_csv("ABSemp.csv")  |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date, -`96 Total`)
alldata <- alldata_init|>
filter(Quarter <= yearquarter("2020 Q1")) |>
select(-Quarter)
# generate the total number
alldata <- alldata |>
mutate(`96 Total` = rowSums(alldata[,1:ncol(alldata)]))
# generate the total amount of the data
rawdata <- as.matrix(alldata) # Remove the NA values due to the loading of the data.
logdata <- log(rawdata)
d4logdata <- 100*(logdata[5:nrow(logdata),]-logdata[1:(nrow(logdata)-4),]) %>% as.matrix()
summary(d4logdata)  # check summary to see if data are read correctly
N=dim(d4logdata)[2]
p=4
# generate the phi of your estimated model
phi <- read.csv("phi_lambda_00808.csv",header=FALSE) %>% as.matrix #estimated parameters produced by MATLAB code
n = nrow(d4logdata)
k = ncol(d4logdata)
# For users, you have to replace the numbers phi if you really want to build up another type of model
# The phi is produced using MATLAB MAIN.m file, please run that file to generate the estimated coefficients.
rawhat = matrix(0,n+4,k)
yhat = matrix(0,n,k)
sdiff = matrix(0,n+4,k)
for (i in 2:n){
for (j in 1:(k-1)){
yhat[i,j]= phi[1,j] + t(d4logdata[(i-1),]) %*% phi[2:86,j]
}
rawhatv = rawdata[i,1:(k-1)] * exp(yhat[i,1:(k-1)]/100) # back transform
yhat[i,k]=100*log(sum(rawhatv)/rawdata[i,k])
rawhat[i+4,] = rawdata[i,1:k] * exp(yhat[i,1:k]/100)
sdiff[i+4,] = exp(yhat[i,1:k]/100)
}
test <- rawhat[-c(1:5),] - rawdata[-c(1:5),]
dd_origin = as.yearqtr(1986 + seq(0,136)/4)
origin_fore <- data.frame(dd_origin, "Estimated" = rawhat[-c(1:5),85] , `Actual`= as_tibble(alldata[-c(1:5),85]))
# Compute the original data
origin_fore |>
ggplot(aes(x = dd_origin, y = Estimated))+ geom_line(colour = "Blue") + geom_line(aes(y =`X96.Total`))
# Elvis Yang
# June 2022
# This is the program computes the multipliers and contrafactural or scenario forecasting
library(matrixStats)
library(ggplot2)
library(zoo)
library(tidyverse)
library(dplyr)
library(stats)
library(readr)
library(pracma)
library(lubridate)
library(fpp3)
library(ggpubr)
# generate the circular plots
library(viridis)
# Donut plot
library(lessR)
# clean the data and reset the total employment by removing the NFD data
alldata_init <- readr::read_csv("ABSemp.csv")  |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date, -`96 Total`)
alldata <- alldata_init|>
filter(Quarter <= yearquarter("2020 Q1")) |>
select(-Quarter)
# generate the total number
alldata <- alldata |>
mutate(`96 Total` = rowSums(alldata[,1:ncol(alldata)]))
# generate the total amount of the data
rawdata <- as.matrix(alldata) # Remove the NA values due to the loading of the data.
logdata <- log(rawdata)
d4logdata <- 100*(logdata[5:nrow(logdata),]-logdata[1:(nrow(logdata)-4),]) %>% as.matrix()
summary(d4logdata)  # check summary to see if data are read correctly
N=dim(d4logdata)[2]
p=4
# generate the phi of your estimated model
phi <- read.csv("phi_lambda_00808.csv",header=FALSE) %>% as.matrix #estimated parameters produced by MATLAB code
n = nrow(d4logdata)
k = ncol(d4logdata)
# For users, you have to replace the numbers phi if you really want to build up another type of model
# The phi is produced using MATLAB MAIN.m file, please run that file to generate the estimated coefficients.
rawhat = matrix(0,n+4,k)
yhat = matrix(0,n,k)
sdiff = matrix(0,n+4,k)
# Elvis Yang
# June 2022
# This is the program computes the multipliers and contrafactural or scenario forecasting
library(matrixStats)
library(ggplot2)
library(zoo)
library(tidyverse)
library(dplyr)
library(stats)
library(readr)
library(pracma)
library(lubridate)
library(fpp3)
library(ggpubr)
# generate the circular plots
library(viridis)
# Donut plot
library(lessR)
# clean the data and reset the total employment by removing the NFD data
alldata_init <- readr::read_csv("ABSemp.csv")  |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date, -`96 Total`)
alldata <- alldata_init|>
filter(Quarter <= yearquarter("2020 Q1")) |>
select(-Quarter)
# generate the total number
alldata <- alldata |>
mutate(`96 Total` = rowSums(alldata[,1:ncol(alldata)]))
# generate the total amount of the data
rawdata <- as.matrix(alldata) # Remove the NA values due to the loading of the data.
logdata <- log(rawdata)
d4logdata <- 100*(logdata[5:nrow(logdata),]-logdata[1:(nrow(logdata)-4),]) %>% as.matrix()
summary(d4logdata)  # check summary to see if data are read correctly
N=dim(d4logdata)[2]
p=4
# generate the phi of your estimated model
phi <- read.csv("phi_lambda_00808.csv",header=FALSE) %>% as.matrix #estimated parameters produced by MATLAB code
n = nrow(d4logdata)
k = ncol(d4logdata)
# For users, you have to replace the numbers phi if you really want to build up another type of model
# The phi is produced using MATLAB MAIN.m file, please run that file to generate the estimated coefficients.
rawhat = matrix(0,n+4,k)
yhat = matrix(0,n,k)
sdiff = matrix(0,n+4,k)
View(rawhat)
for (i in 2:n){
for (j in 1:(k-1)){
yhat[i,j]= phi[1,j] + t(d4logdata[(i-1),]) %*% phi[2:86,j]
}
rawhatv = rawdata[i,1:(k-1)] * exp(yhat[i,1:(k-1)]/100) # back transform
yhat[i,k]=100*log(sum(rawhatv)/rawdata[i,k])
rawhat[i+4,] = rawdata[i,1:k] * exp(yhat[i,1:k]/100)
sdiff[i+4,] = exp(yhat[i,1:k]/100)
}
View(yhat)
View(rawdata)
ggplot()+
geom_line(data = unemp_plot, aes(x = Quarter,y = Unemploment.Rate), colour = "blue",linetype = "dashed")+
geom_line(data = cont_data[-9,], aes(x= Quarter,y=Unemployment_Rate),colour="red")+
labs(title = "Counterfactual Analysis of the Unemployment Rate in Australia",
subtitle = "From 1984 Q1 to 2022 Q2",
y = "Unemployment Rate",
caption = "Note: Red line is Forecast values; Blue line is actual values")
library(matrixStats)
library(ggplot2)
library(zoo)
library(tidyverse)
library(dplyr)
library(stats)
library(ggpubr)
library(readxl)
library(pracma)
library(lubridate)
library(fpp3)
labour <- read_csv("total_labour_force_monthly.csv")
employment <- read_csv("ABSemp.csv")
oneemp <- read_csv("oneemp.csv")
NFD_data<- read_csv("NFD_data.csv")
NFD <- NFD_data$Total
empfore<- oneemp$`96 Total`
cont_emp <- oneemp$Employment
tot_postcov <- employment |>
select(Date,`96 Total`) |>
mutate(Quarter = yearquarter(my(Date))) |>
filter(Quarter > yearquarter("2020 Q1"))
ts_labour <- labour |>
filter(month(my(Date)) %in% c(2,5,8,11)) |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date) |>
as_tsibble(index = Quarter)
ts_labour <- ts_labour |>
filter(Quarter >= yearquarter("1984 Q4") & Quarter <= yearquarter("2022 Q2")  )
# ts_labour$labour_force = ts_labour$labour_force - NFD
pre_2020 <- ts_labour |>
filter(Quarter <= yearquarter("2020 Q1"))
post_2020 <- ts_labour|>
filter(Quarter > yearquarter("2020 Q1"))
fc_model <- pre_2020 |>
model(stepwise = ARIMA(labour_force))
fc_emp<- fc_model |>
forecast(h=9)
#
# fc_emp_aftercovid <- fc_emp |>
#   filter(month(Month) %in% c(2,5,8,11))
plabour1<- fc_emp|>
autoplot(ts_labour) +
labs(x = "Quarter", y = "Total Labour Force",
title = "Forecasts of total labour force in Australia",
subtitle = "Black: Actual Data")
# zoomed ones
plabour2<- fc_emp|>
filter(Quarter > yearquarter("2020 Q1") & Quarter <= yearquarter("2022 Q2"))|>
autoplot(post_2020) +
labs(x = "Quarter", y = "Total Labour Force",
title = "Forecasts of total labour force in Australia",
subtitle = "Data Range from 2020 Q2 to 2022 Q1",
caption = "Black: Actual Datal; Data Range till 2022 Q1")
ggarrange(plabour1,plabour2)
# accumulative loss
acc_LOSS <- colSums(as.matrix(fc_emp$.mean - post_2020$labour_force))
fc_emp$.mean / post_2020$labour_force
# real unemployment rate
(post_2020$labour_force - tot_postcov$`96 Total`)/post_2020$labour_force
# real unemployment rate using forecast values
(post_2020$labour_force[1:9] - empfore)/post_2020$labour_force[1:9]
# contrafactual unemployment rate
contfac_unemp<- (fc_emp$.mean - cont_emp)/fc_emp$.mean
upper_cont <- (fc_emp$.mean - oneemp$upper_bound)/fc_emp$.mean
lower_cont <- (fc_emp$.mean - oneemp$lower_bound)/fc_emp$.mean
cont_data<- data.frame(Quarter= yearquarter(post_2020$Quarter[1:9]),
Unemployment_Rate = as.matrix(contfac_unemp) )
## Make the unemployment rate plot for comparison
tsemp <- employment |>
select(Date,`96 Total`) |>
mutate(Quarter = yearquarter(my(Date)))
fitsemp <- ts_labour |>
filter(Quarter >= yearquarter("1984 Q4") & Quarter <= yearquarter("2022 Q2"))
unemployment <- (as.matrix(fitsemp$labour_force) - as.matrix(tsemp$`96 Total`))/as.matrix(fitsemp$labour_force)
unemp_plot<- data.frame( `Unemploment Rate`= as.matrix(unemployment),Quarter = yearquarter(tsemp$Quarter))
data1 <- dplyr::bind_rows(unemp_plot, cont_data)
colors <- c("Actual" = "blue", "Forecasts" = "red")
ggplot()+
geom_line(data = unemp_plot, aes(x = Quarter,y = Unemploment.Rate), colour = "blue",linetype = "dashed")+
geom_line(data = cont_data[-9,], aes(x= Quarter,y=Unemployment_Rate),colour="red")+
labs(title = "Counterfactual Analysis of the Unemployment Rate in Australia",
subtitle = "From 1984 Q1 to 2022 Q2",
y = "Unemployment Rate",
caption = "Note: Red line is Forecast values; Blue line is actual values")
