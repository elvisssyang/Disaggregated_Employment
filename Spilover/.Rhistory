cnmb<-nrow(y)-i
Z<-y[rnmb:cnmb,]
X<-cbind(X,Z)
}
# constant to stack at last
X<-cbind(X,ones(T,1))
# This is to set prior
small_sig2=zeros(N,1)
Stack_AR_coeff=zeros(p,N)
for(i in c(1:N)){
#calculate variance for each equation to set pror
#by fitting an AR(4) per equation
c(~,small_sig2[i,1])=olsvar(y[,i],4)
ARcoeff = olsvar(y[,i],1)
if (ARcoeff >= 0.8){
Stack_AR_coeff(1,i) = 1}
# run an AR(1) to set to random walk if time series is persistant
# (>0.8)
}
Y_d = rbind(matrix(0,N*p,N), diag(sqrt(small_sig2/lambda)))
for (i in 1:p){
Y_d[(i-1)*N+1:i*N, ] <- diag(Stack_AR_coeff[i,]*repmat(1,N,1)*sqrt(small_sig))/lambda
}
X_d = rbind(kron(diag(1:P) , diag(sqrt(small_sig2) / lambda)) , zeros(N,K-1))
X_d[size(X_d,1)+1,K] = 1e-10
Y_d <- rbind(Y_d,zeros(1,N))
# Do least square to get posterior
Y_star = rbind(Y,Y_d)
X_star = rbind(X,X_d)
# Get posterior mode/mean of VAR coefficients
phi = mldivide(t(X_star) %*% X_star , t(X_star) %*% Y_star)
e = Y - X %*% phi
e_star = Y_star - X_star %*% phi
# Posterior mode/mean of covariance matrix
SIGMA = mrdivide((t(e_star) %*% e_star), (size(Y_star,1) - size(phi,1)))
# rearrange phi and X to just make constant in first row
# phi = rbind(phi[nrow(phi)])
#
# X =
return(phi)
}
BVAR<-function(y,p,lambda){
T=dim(y)[1]
N=dim(y)[2]
#backcast data with the mean
y<-rbind(repmat(colMeans(y),p,1),y)
K=p*N+1
#create data matrics
Y<-y[-1:-(p),]
X=c()
for(i in 1:p){
rnmb<-p+1-i
cnmb<-nrow(y)-i
Z<-y[rnmb:cnmb,]
X<-cbind(X,Z)
}
# constant to stack at last
X<-cbind(X,ones(T,1))
# This is to set prior
small_sig2=zeros(N,1)
Stack_AR_coeff=zeros(p,N)
for(i in c(1:N)){
#calculate variance for each equation to set pror
#by fitting an AR(4) per equation
c(~,small_sig2[i,1])=olsvar(y[,i],4)
ARcoeff = olsvar(y[,i],1)
if (ARcoeff >= 0.8){
Stack_AR_coeff(1,i) = 1}
# run an AR(1) to set to random walk if time series is persistant
# (>0.8)
}
Y_d = rbind(matrix(0,N*p,N), diag(sqrt(small_sig2/lambda)))
for (i in 1:p){
Y_d[(i-1)*N+1:i*N, ] <- diag(Stack_AR_coeff[i,]*repmat(1,N,1)*sqrt(small_sig))/lambda
}
X_d = rbind(kron(diag(1:P) , diag(sqrt(small_sig2) / lambda)) , zeros(N,K-1))
X_d[size(X_d,1)+1,K] = 1e-10
Y_d <- rbind(Y_d,zeros(1,N))
# Do least square to get posterior
Y_star = rbind(Y,Y_d)
X_star = rbind(X,X_d)
# Get posterior mode/mean of VAR coefficients
phi = mldivide(t(X_star) %*% X_star , t(X_star) %*% Y_star)
return(phi)
e = Y - X %*% phi
e_star = Y_star - X_star %*% phi
# Posterior mode/mean of covariance matrix
SIGMA = mrdivide((t(e_star) %*% e_star), (size(Y_star,1) - size(phi,1)))
# rearrange phi and X to just make constant in first row
# phi = rbind(phi[nrow(phi)])
#
# X =
}
BVAR<-function(y,p,lambda){
T=dim(y)[1]
N=dim(y)[2]
#backcast data with the mean
y<-rbind(repmat(colMeans(y),p,1),y)
K=p*N+1
#create data matrics
Y<-y[-1:-(p),]
X=c()
for(i in 1:p){
rnmb<-p+1-i
cnmb<-nrow(y)-i
Z<-y[rnmb:cnmb,]
X<-cbind(X,Z)
}
# constant to stack at last
X<-cbind(X,ones(T,1))
# This is to set prior
small_sig2=zeros(N,1)
Stack_AR_coeff=zeros(p,N)
for(i in c(1:N)){
#calculate variance for each equation to set pror
#by fitting an AR(4) per equation
c(~,small_sig2[i,1])=olsvar(y[,i],4)
ARcoeff = olsvar(y[,i],1)
if (ARcoeff >= 0.8){
Stack_AR_coeff(1,i) = 1}
# run an AR(1) to set to random walk if time series is persistant
# (>0.8)
}
Y_d = rbind(matrix(0,N*p,N), diag(sqrt(small_sig2/lambda)))
for (i in 1:p){
Y_d[(i-1)*N+1:i*N, ] <- diag(Stack_AR_coeff[i,]*repmat(1,N,1)*sqrt(small_sig))/lambda
}
X_d = rbind(kron(diag(1:P) , diag(sqrt(small_sig2) / lambda)) , zeros(N,K-1))
X_d[size(X_d,1)+1,K] = 1e-10
Y_d <- rbind(Y_d,zeros(1,N))
# Do least square to get posterior
Y_star = rbind(Y,Y_d)
X_star = rbind(X,X_d)
# Get posterior mode/mean of VAR coefficients
phi = mldivide(t(X_star) %*% X_star , t(X_star) %*% Y_star)
return(phi)
e = Y - X %*% phi
e_star = Y_star - X_star %*% phi
# Posterior mode/mean of covariance matrix
SIGMA = mrdivide((t(e_star) %*% e_star), (size(Y_star,1) - size(phi,1)))
# rearrange phi and X to just make constant in first row
# phi = rbind(phi[nrow(phi)])
#
# X =
}
BVAR<-function(y,p,lambda){
T=dim(y)[1]
N=dim(y)[2]
#backcast data with the mean
y<-rbind(repmat(colMeans(y),p,1),y)
K=p*N+1
#create data matrics
Y<-y[-1:-(p),]
X=c()
for(i in 1:p){
rnmb<-p+1-i
cnmb<-nrow(y)-i
Z<-y[rnmb:cnmb,]
X<-cbind(X,Z)
}
# constant to stack at last
X<-cbind(X,ones(T,1))
# This is to set prior
small_sig2=zeros(N,1)
Stack_AR_coeff=zeros(p,N)
for(i in c(1:N)){
#calculate variance for each equation to set pror
#by fitting an AR(4) per equation
c(~,small_sig2[i,1])=olsvar(y[,i],4)
ARcoeff = olsvar(y[,i],1)
if (ARcoeff >= 0.8){
Stack_AR_coeff(1,i) = 1}
# run an AR(1) to set to random walk if time series is persistant
# (>0.8)
}
Y_d = rbind(matrix(0,N*p,N), diag(sqrt(small_sig2/lambda)))
for (i in 1:p){
Y_d[(i-1)*N+1:i*N, ] <- diag(Stack_AR_coeff[i,]*repmat(1,N,1)*sqrt(small_sig))/lambda
}
X_d = rbind(kron(diag(1:P) , diag(sqrt(small_sig2) / lambda)) , zeros(N,K-1))
X_d[size(X_d,1)+1,K] = 1e-10
Y_d <- rbind(Y_d,zeros(1,N))
# Do least square to get posterior
Y_star = rbind(Y,Y_d)
X_star = rbind(X,X_d)
# Get posterior mode/mean of VAR coefficients
phi = mldivide(t(X_star) %*% X_star , t(X_star) %*% Y_star)
e = Y - X %*% phi
e_star = Y_star - X_star %*% phi
# Posterior mode/mean of covariance matrix
SIGMA = mrdivide((t(e_star) %*% e_star), (size(Y_star,1) - size(phi,1)))
# rearrange phi and X to just make constant in first row
# phi = rbind(phi[nrow(phi)])
#
# X =
print(phi)
}
phi <- BVAR(d4logdata,p,lambda)
alldata[1:2,]
BVAR<-function(y,p,lambda){
T=dim(y)[1]
N=dim(y)[2]
#backcast data with the mean
y<-rbind(repmat(colMeans(y),p,1),y)
K=p*N+1
#create data matrics
Y<-y[-1:-(p),]
X=c()
for(i in 1:p){
rnmb<-p+1-i
cnmb<-nrow(y)-i
Z<-y[rnmb:cnmb,]
X<-cbind(X,Z)
}
# constant to stack at last
X<-cbind(X,ones(T,1))
# This is to set prior
small_sig2=zeros(N,1)
Stack_AR_coeff=zeros(p,N)
for(i in c(1:N)){
#calculate variance for each equation to set pror
#by fitting an AR(4) per equation
c(~,small_sig2[i,1])=olsvar(y[,i],4)
ARcoeff = olsvar(y[,i],1)
if (ARcoeff >= 0.8){
Stack_AR_coeff(1,i) = 1}
# run an AR(1) to set to random walk if time series is persistant
# (>0.8)
}
Y_d = rbind(matrix(0,N*p,N), diag(sqrt(small_sig2/lambda)))
for (i in 1:p){
Y_d[(i-1)*N+1:i*N, ] <- diag(Stack_AR_coeff[i,]*repmat(1,N,1)*sqrt(small_sig))/lambda
}
X_d = rbind(kron(diag(1:P) , diag(sqrt(small_sig2) / lambda)) , zeros(N,K-1))
X_d[size(X_d,1)+1,K] = 1e-10
Y_d <- rbind(Y_d,zeros(1,N))
# Do least square to get posterior
Y_star = rbind(Y,Y_d)
X_star = rbind(X,X_d)
# Get posterior mode/mean of VAR coefficients
phi = mldivide(t(X_star) %*% X_star , t(X_star) %*% Y_star)
e = Y - X %*% phi
e_star = Y_star - X_star %*% phi
# Posterior mode/mean of covariance matrix
SIGMA = mrdivide((t(e_star) %*% e_star), (size(Y_star,1) - size(phi,1)))
# rearrange phi and X to just make constant in first row
phi = rbind(phi[nrow(phi),],phi[1:nrow(phi)-1,])
X = cbind(X[,ncol(X)],X[,1:ncol(X)-1])
return(phi)
}
library(pracma)
library(tidyverse)
BVAR<-function(y,p,lambda){
T=dim(y)[1]
N=dim(y)[2]
#backcast data with the mean
y<-rbind(repmat(colMeans(y),p,1),y)
K=p*N+1
#create data matrics
Y<-y[-1:-(p),]
X=c()
for(i in 1:p){
rnmb<-p+1-i
cnmb<-nrow(y)-i
Z<-y[rnmb:cnmb,]
X<-cbind(X,Z)
}
# constant to stack at last
X<-cbind(X,ones(T,1))
# This is to set prior
small_sig2=zeros(N,1)
Stack_AR_coeff=zeros(p,N)
for(i in c(1:N)){
#calculate variance for each equation to set pror
#by fitting an AR(4) per equation
c(~,small_sig2[i,1])=olsvar(y[,i],4)
ARcoeff = olsvar(y[,i],1)
if (ARcoeff >= 0.8){
Stack_AR_coeff(1,i) = 1}
# run an AR(1) to set to random walk if time series is persistant
# (>0.8)
}
Y_d = rbind(matrix(0,N*p,N), diag(sqrt(small_sig2/lambda)))
for (i in 1:p){
Y_d[(i-1)*N+1:i*N, ] <- diag(Stack_AR_coeff[i,]*repmat(1,N,1)*sqrt(small_sig))/lambda
}
X_d = rbind(kron(diag(1:P) , diag(sqrt(small_sig2) / lambda)) , zeros(N,K-1))
X_d[size(X_d,1)+1,K] = 1e-10
Y_d <- rbind(Y_d,zeros(1,N))
# Do least square to get posterior
Y_star = rbind(Y,Y_d)
X_star = rbind(X,X_d)
# Get posterior mode/mean of VAR coefficients
phi = mldivide(t(X_star) %*% X_star , t(X_star) %*% Y_star)
e = Y - X %*% phi
e_star = Y_star - X_star %*% phi
# Posterior mode/mean of covariance matrix
SIGMA = mrdivide((t(e_star) %*% e_star), (size(Y_star,1) - size(phi,1)))
# rearrange phi and X to just make constant in first row
phi = rbind(phi[nrow(phi),],phi[1:nrow(phi)-1,])
X = cbind(X[,ncol(X)],X[,1:ncol(X)-1])
return(phi)
}
for(i in c(1:p)){
Z=y[c(p+1-i:nrow(y)-i),]
X<-cbind(X,Z)
}
BVAR<-function(y,p,lambda){
T=dim(y)[1]
N=dim(y)[2]
#backcast data with the mean
y<-rbind(repmat(colMeans(y),p,1),y)
K=p*N+1
#create data matrics
Y<-y[-1:-(p),]
X=c()
for(i in 1:p){
rnmb<-p+1-i
cnmb<-nrow(y)-i
Z<-y[rnmb:cnmb,]
X<-cbind(X,Z)
}
# constant to stack at last
X<-cbind(X,ones(T,1))
# This is to set prior
small_sig2=zeros(N,1)
Stack_AR_coeff=zeros(p,N)
for(i in c(1:N)){
#calculate variance for each equation to set pror
#by fitting an AR(4) per equation
c(~,small_sig2[i,1])=olsvar(y[,i],4)
ARcoeff = olsvar(y[,i],1)
if (ARcoeff >= 0.8){
Stack_AR_coeff(1,i) = 1}
# run an AR(1) to set to random walk if time series is persistant
# (>0.8)
}
Y_d = rbind(matrix(0,N*p,N), diag(sqrt(small_sig2/lambda)))
for (i in 1:p){
Y_d[(i-1)*N+1:i*N, ] <- diag(Stack_AR_coeff[i,]*repmat(1,N,1)*sqrt(small_sig))/lambda
}
X_d = rbind(kron(diag(1:P) , diag(sqrt(small_sig2) / lambda)) , zeros(N,K-1))
X_d[size(X_d,1)+1,K] = 1e-10
Y_d <- rbind(Y_d,zeros(1,N))
# Do least square to get posterior
Y_star = rbind(Y,Y_d)
X_star = rbind(X,X_d)
# Get posterior mode/mean of VAR coefficients
phi = mldivide(t(X_star) %*% X_star , t(X_star) %*% Y_star)
e = Y - X %*% phi
e_star = Y_star - X_star %*% phi
# Posterior mode/mean of covariance matrix
SIGMA = mrdivide((t(e_star) %*% e_star), (size(Y_star,1) - size(phi,1)))
# rearrange phi and X to just make constant in first row
phi = rbind(phi[nrow(phi),],phi[1:nrow(phi)-1,])
X = cbind(X[,ncol(X)],X[,1:ncol(X)-1])
return(phi)
}
BVAR<-function(y,p,lambda){
T=dim(y)[1]
N=dim(y)[2]
#backcast data with the mean
y <- rbind(repmat(colMeans(y),p,1),y)
K=p*N+1
#create data matrics
Y<-y[-1:-(p),]
X=c()
for(i in 1:p){
rnmb<-p+1-i
cnmb<-nrow(y)-i
Z<-y[rnmb:cnmb,]
X<-cbind(X,Z)
}
# constant to stack at last
X<-cbind(X,ones(T,1))
# This is to set prior
small_sig2=zeros(N,1)
Stack_AR_coeff=zeros(p,N)
for(i in c(1:N)){
#calculate variance for each equation to set pror
#by fitting an AR(4) per equation
c(~,small_sig2[i,1])=olsvar(y[,i],4)
ARcoeff = olsvar(y[,i],1)
if (ARcoeff >= 0.8){
Stack_AR_coeff(1,i) = 1}
# run an AR(1) to set to random walk if time series is persistant
# (>0.8)
}
Y_d = rbind(matrix(0,N*p,N), diag(sqrt(small_sig2/lambda)))
for (i in 1:p){
Y_d[(i-1)*N+1:i*N, ] <- diag(Stack_AR_coeff[i,]*repmat(1,N,1)*sqrt(small_sig))/lambda
}
X_d = rbind(kron(diag(1:P) , diag(sqrt(small_sig2) / lambda)) , zeros(N,K-1))
X_d[size(X_d,1)+1,K] = 1e-10
Y_d <- rbind(Y_d,zeros(1,N))
# Do least square to get posterior
Y_star = rbind(Y,Y_d)
X_star = rbind(X,X_d)
# Get posterior mode/mean of VAR coefficients
phi = mldivide(t(X_star) %*% X_star , t(X_star) %*% Y_star)
e = Y - X %*% phi
e_star = Y_star - X_star %*% phi
# Posterior mode/mean of covariance matrix
SIGMA = mrdivide((t(e_star) %*% e_star), (size(Y_star,1) - size(phi,1)))
# rearrange phi and X to just make constant in first row
phi = rbind(phi[nrow(phi),],phi[1:nrow(phi)-1,])
X = cbind(X[,ncol(X)],X[,1:ncol(X)-1])
print(phi)
}
BVAR<-function(y,p,lambda){
T=dim(y)[1]
N=dim(y)[2]
#backcast data with the mean
y <- rbind(repmat(colMeans(y),p,1),y)
K=p*N+1
#create data matrics
Y<-y[-1:-(p),]
X=c()
for(i in 1:p){
rnmb<-p+1-i
cnmb<-nrow(y)-i
Z<-y[rnmb:cnmb,]
X<-cbind(X,Z)
}
# constant to stack at last
X<-cbind(X,ones(T,1))
# This is to set prior
small_sig2=zeros(N,1)
Stack_AR_coeff=zeros(p,N)
for(i in c(1:N)){
#calculate variance for each equation to set pror
#by fitting an AR(4) per equation
c(~,small_sig2[i,1])=olsvar(y[,i],4)
ARcoeff = olsvar(y[,i],1)
if (ARcoeff >= 0.8){
Stack_AR_coeff(1,i) = 1}
# run an AR(1) to set to random walk if time series is persistant
# (>0.8)
}
Y_d = rbind(matrix(0,N*p,N), diag(sqrt(small_sig2/lambda)))
for (i in 1:p){
Y_d[(i-1)*N+1:i*N, ] <- diag(Stack_AR_coeff[i,]*repmat(1,N,1)*sqrt(small_sig))/lambda
}
X_d = rbind(kron(diag(1:P) , diag(sqrt(small_sig2) / lambda)) , zeros(N,K-1))
X_d[size(X_d,1)+1,K] = 1e-10
Y_d <- rbind(Y_d,zeros(1,N))
# Do least square to get posterior
Y_star = rbind(Y,Y_d)
X_star = rbind(X,X_d)
# Get posterior mode/mean of VAR coefficients
phi = mldivide(t(X_star) %*% X_star , t(X_star) %*% Y_star)
e = Y - X %*% phi
e_star = Y_star - X_star %*% phi
# Posterior mode/mean of covariance matrix
SIGMA = mrdivide((t(e_star) %*% e_star), (size(Y_star,1) - size(phi,1)))
# rearrange phi and X to just make constant in first row
phi = rbind(phi[nrow(phi),],phi[1:nrow(phi)-1,])
X = cbind(X[,ncol(X)],X[,1:ncol(X)-1])
print(phi)
}
# generate the total amount of the data
rawdata <- as.matrix(alldata) # Remove the NA values due to the loading of the data.
logdata <- log(rawdata)
d4logdata <- 100*(logdata[5:nrow(logdata),]-logdata[1:(nrow(logdata)-4),]) %>% as.matrix()
View(rawdata)
# generate the total amount of the data
rawdata <- as.matrix(alldata) # Remove the NA values due to the loading of the data.
logdata <- log(rawdata)
d4logdata <- 100*(logdata[5:nrow(logdata),]-logdata[1:(nrow(logdata)-4),]) %>% as.matrix()
library(matrixStats)
library(ggploot2)
library(matrixStats)
library(ggplot2)
library(zoo)
library(tidyverse)
library(dplyr)
library(stats)
library(readxl)
library(pracma)
library(tidyverse)
alldata <- readr::read_csv("ABSemp.csv")
# generate the total amount of the data
rawdata <- as.matrix(alldata) # Remove the NA values due to the loading of the data.
logdata <- log(rawdata)
d4logdata <- 100*(logdata[5:nrow(logdata),]-logdata[1:(nrow(logdata)-4),]) %>% as.matrix()
summary(d4logdata)  # check summary to see if data are read correctly
N=dim(d4logdata)[2]
p=4
lambda=0.2 # shrinkage
maxhor=2 # maximum forecast horizon where we are imposing conditions
View(d4logdata)
phi <- read.csv("phi.csv",header=FALSE) %>% as.matrix #estimated parameters produced by MATLAB code
n = nrow(d4logdata)
k = ncol(d4logdata)
# For users, you have to replace the numbers phi if you really want to build up another type of model
# The phi is produced using MATLAB MAIN.m file, please run that file to generate the estimated coefficients.
# Here the phi are divided to give four lags and one constant.
# phi[1,j] for constant, the rest are multiplied by the four lags and do the estimation
rawhat = matrix(0,n,k)
yhat = matrix(0,n,k)
sdiff = matrix(0,n,k)
i=5
for (j in 1:(k-1)){
yhat[i,j]= phi[1,j] + t(d4logdata[(i-1),]) %*% phi[2:86,j] + t(d4logdata[(i-2),]) %*% phi[87:171,j] + t(d4logdata[(i-3),]) %*% phi[172:256,j] + t(d4logdata[(i-4),]) %*%
phi[257:341,j] # y_t = y_{t-1}+y_{t-1}+y{t-3}+y_{t-4}
}
rawhatv = rawdata[(i-4),1:(k-1)] * exp(yhat[i,1:(k-1)]/100) # back transform
yhat[i,k]=100*log(sum(rawhatv)/rawdata[(i-4),k])
rawhat[i,] = rawdata[(i-4),1:k] * exp(yhat[i,1:k]/100)
sdiff[i,] = exp(yhat[i,1:k]/100)
sum(rawhatv)
rawdata[(i-4),k]
