rawhat = matrix(0,n,k)
yhat = matrix(0,n,k)
sdiff = matrix(0,n,k)
for (i in 2:n){
for (j in 1:(k-1)){
yhat[i,j]= phi[1,j] + t(d4logdata[(i-1),]) %*% phi[2:86,j]
}
rawhatv = rawdata[(i-1),1:(k-1)] * exp(yhat[i,1:(k-1)]/100) # back transform
yhat[i,k]=100*log(sum(rawhatv)/rawdata[(i-1),k])
rawhat[i,] = rawdata[(i-1),1:k] * exp(yhat[i,1:k]/100)
sdiff[i,] = exp(yhat[i,1:k]/100)
}
# Conduct our multiplier analysis
# The row we set 44 is 4(4 last observations to start forecasting) + 40(10 years horizon of forecasting)
multiraw = matrix(0,44,k)
multiraw[1:4,]=rawdata[(nrow(rawdata)-3):nrow(rawdata),]
multig = matrix(0,44,k)
multilevels = matrix(0,44,k-1) # matrix that saves the evolution of total employment in reaction to 1 percent point shock in each sector
multigrowth = matrix(0,44,k-1) # matrix that saves the evolution of employment growth in reaction to 1 percentage point shock in each sector
sector = 1
i = 5
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
View(multig)
multiraw[i,1:(k-1)] = multiraw[(i-4),1:(k-1)]*exp(multig[i,1:(k-1)]/100)
View(multiraw)
multiraw[i,k] = sum(multiraw[i,1:(k-1)])
multiraw[i,k]/multiraw[(i-4),k]
multig[i,k]=100*log(multiraw[i,k]/multiraw[(i-4),k])
i=6
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
multiraw[i,1:(k-1)] = multiraw[(i-4),1:(k-1)]*exp(multig[i,1:(k-1)]/100)
multiraw[i,k] = sum(multiraw[i,1:(k-1)])
multiraw[i,k]/multiraw[(i-4),k]
log(multiraw[i,k]/multiraw[(i-4),k])
log(0.9990777)
log(1)
log(0.8)
# multiplier analysis
multiraw = matrix(0,44,k)
multiraw[1:4,]=rawdata[(nrow(rawdata)-3):nrow(rawdata),]
multig = matrix(0,44,k)
multilevels = matrix(0,44,k-1) #matrix that saves the evolution of total employment in reaction to 1 percentage point shock in each sector
multigrowth = matrix(0,44,k-1) #matrix that saves the evolution of employment growth in reaction to 1 percentage point shock in each sector
for (sector in 1:(k-1)){
for (i in 5:44){
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
multiraw[i,1:(k-1)] = multiraw[(i-4),1:(k-1)]*exp(multig[i,1:(k-1)]/100)
multiraw[i,k] = sum(multiraw[i,1:(k-1)])
multig[i,k]=100*log(multiraw[i,k]/multiraw[(i-4),k])
}
multilevels[,sector]=multiraw[,k]
multigrowth[,sector]=multig[,k]
}
multipliers = colSums(multigrowth)/4 # division by 4 is necessary because of seasonal differences
mpers = colCumsums(multigrowth[5:44,])/4 #colCumsums() is a function in matrixStats package
shares=colSums(rawdata[(nrow(rawdata)-3):nrow(rawdata),1:84])/sum(rawdata[(nrow(rawdata)-3):nrow(rawdata),85]) #sector shares estimated like this to eliminate the effect of seasonality
mtplier <- rbind(shares,mpers)
View(mtplier)
multiraw = matrix(0,44,k)
multiraw[1:4,]=rawdata[(nrow(rawdata)-3):nrow(rawdata),]
multig = matrix(0,44,k)
multilevels = matrix(0,44,k-1) # matrix that saves the evolution of total employment in reaction to 1 percent point shock in each sector
multigrowth = matrix(0,44,k-1) # matrix that saves the evolution of employment growth in reaction to 1 percentage point shock in each sector
for (sector in 1:(k-1)){
for (i in 5:44){
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
multiraw[i,1:(k-1)] = multiraw[(i-4),1:(k-1)]*exp(multig[i,1:(k-1)]/100)
multiraw[i,k] = sum(multiraw[i,1:(k-1)])
multig[i,k]=100*log(multiraw[i,k]/multiraw[(i-4),k]) # ???? why here need to take log
}
multilevels[,sector]=multiraw[,k]
multigrowth[,sector]=multig[,k]
}
multipliers = colSums(multigrowth)/4 # division by 4 is necessary because of seasonal differences
mpers = colCumsums(multigrowth[5:44,])/4 #colCumsums() is a function in matrixStats package
shares=colSums(rawdata[(nrow(rawdata)-3):nrow(rawdata),1:84])/sum(rawdata[(nrow(rawdata)-3):nrow(rawdata),85]) #sector shares estimated like this to eliminate the effect of seasonality
mtplers <- rbind(shares,mpers)
write.csv(file="multipliers_1.csv",rbind(shares,mpers))
View(mtplers)
View(mpers)
View(mtplier)
mtplers == mtplier
View(multig)
# Elvis Yang
# June 2022
# This is the program computes the multipliers and contrafactural or scenario forecasting
library(matrixStats)
library(ggplot2)
library(zoo)
library(tidyverse)
library(dplyr)
library(stats)
library(readxl)
library(pracma)
library(tidyverse)
library(lubridate)
library(fpp3)
# INPUTS
# y  Time series
#p lags
# varagin There are the(optional) bootstrapping options
# 'parametric'   Draw residuals parametrically from the covariance matrix
# 'bootstrap_with _replacement'  Draw residuals randomly from the empirical residuals
# 'double_bootstrap'   Bias correction boostrap-after -bootstrap
# 'wild_bootstrap' Allws for hetroskedasticity by multiplying by a random variable
alldata <- readr::read_csv("ABSemp.csv")  |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date) |>
filter(Quarter <= yearquarter("2019 Q4"))
alldata <- alldata |>
select(-Quarter)
# generate the total amount of the data
rawdata <- as.matrix(alldata) # Remove the NA values due to the loading of the data.
logdata <- log(rawdata)
d4logdata <- 100*(logdata[5:nrow(logdata),]-logdata[1:(nrow(logdata)-4),]) %>% as.matrix()
summary(d4logdata)  # check summary to see if data are read correctly
N=dim(d4logdata)[2]
p=4
lambda=0.2 # shrinkage
maxhor=2 # maximum forecast horizon where we are imposing conditions
# generate the phi of your estimated model
#phi <- BVAR(d4logdata,p,lambda)
phi <- read.csv("phi_2.csv",header=FALSE) %>% as.matrix #estimated parameters produced by MATLAB code
n = nrow(d4logdata)
k = ncol(d4logdata)
# For users, you have to replace the numbers phi if you really want to build up another type of model
# The phi is produced using MATLAB MAIN.m file, please run that file to generate the estimated coefficients.
# Here the phi are divided to give four lags and one constant.
# phi[1,j] for constant, the rest are multiplied by the four lags and do the estimation
rawhat = matrix(0,n,k)
yhat = matrix(0,n,k)
sdiff = matrix(0,n,k)
for (i in 2:n){
for (j in 1:(k-1)){
yhat[i,j]= phi[1,j] + t(d4logdata[(i-1),]) %*% phi[2:86,j]
}
rawhatv = rawdata[(i-1),1:(k-1)] * exp(yhat[i,1:(k-1)]/100) # back transform
yhat[i,k]=100*log(sum(rawhatv)/rawdata[(i-1),k])
rawhat[i,] = rawdata[(i-1),1:k] * exp(yhat[i,1:k]/100)
sdiff[i,] = exp(yhat[i,1:k]/100)
}
multiraw = matrix(0,44,k)
multiraw[1:4,]=rawdata[(nrow(rawdata)-3):nrow(rawdata),]
multig = matrix(0,44,k)
multilevels = matrix(0,44,k-1) # matrix that saves the evolution of total employment in reaction to 1 percent point shock in each sector
multigrowth = matrix(0,44,k-1) # matrix that saves the evolution of employment growth in reaction to 1 percentage point shock in each sector
sector = 1
i = 5
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
multiraw[i,1:(k-1)] = multiraw[(i-4),1:(k-1)]*exp(multig[i,1:(k-1)]/100)
multiraw[i,k] = sum(multiraw[i,1:(k-1)])
multig[i,k]=100*log(multiraw[i,k]/multiraw[(i-4),k]) # ???? why here need to take log, is means log(y_t) - log(y_{t-4})
View(multig)
i = 6
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
multiraw[i,1:(k-1)] = multiraw[(i-4),1:(k-1)]*exp(multig[i,1:(k-1)]/100)
multiraw[i,k] = sum(multiraw[i,1:(k-1)])
multig[i,k]=100*log(multiraw[i,k]/multiraw[(i-4),k]) # ???? why here need to take log, is means log(y_t) - log(y_{t-4})
for (i in 5:44){
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
multiraw[i,1:(k-1)] = multiraw[(i-4),1:(k-1)]*exp(multig[i,1:(k-1)]/100)
multiraw[i,k] = sum(multiraw[i,1:(k-1)])
multig[i,k]=100*log(multiraw[i,k]/multiraw[(i-4),k]) # ???? why here need to take log, is means log(y_t) - log(y_{t-4})
}
View(phi)
source("~/Desktop/hon_proj/Disaggregated_Employment/Spilover/forecast_onelag.R", echo=TRUE)
# Elvis Yang
# June 2022
# This is the program computes the multipliers and contrafactural or scenario forecasting
library(matrixStats)
library(ggplot2)
library(zoo)
library(tidyverse)
library(dplyr)
library(stats)
library(readxl)
library(pracma)
library(tidyverse)
library(lubridate)
library(fpp3)
# INPUTS
# y  Time series
#p lags
# varagin There are the(optional) bootstrapping options
# 'parametric'   Draw residuals parametrically from the covariance matrix
# 'bootstrap_with _replacement'  Draw residuals randomly from the empirical residuals
# 'double_bootstrap'   Bias correction boostrap-after -bootstrap
# 'wild_bootstrap' Allws for hetroskedasticity by multiplying by a random variable
alldata <- readr::read_csv("ABSemp.csv")  |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date) |>
filter(Quarter <= yearquarter("2019 Q4"))
alldata <- alldata |>
select(-Quarter)
# generate the total amount of the data
rawdata <- as.matrix(alldata) # Remove the NA values due to the loading of the data.
logdata <- log(rawdata)
d4logdata <- 100*(logdata[5:nrow(logdata),]-logdata[1:(nrow(logdata)-4),]) %>% as.matrix()
summary(d4logdata)  # check summary to see if data are read correctly
N=dim(d4logdata)[2]
p=4
lambda=0.2 # shrinkage
maxhor=2 # maximum forecast horizon where we are imposing conditions
# generate the phi of your estimated model
#phi <- BVAR(d4logdata,p,lambda)
phi <- read.csv("phi_2.csv",header=FALSE) %>% as.matrix #estimated parameters produced by MATLAB code
n = nrow(d4logdata)
k = ncol(d4logdata)
# For users, you have to replace the numbers phi if you really want to build up another type of model
# The phi is produced using MATLAB MAIN.m file, please run that file to generate the estimated coefficients.
# Here the phi are divided to give four lags and one constant.
# phi[1,j] for constant, the rest are multiplied by the four lags and do the estimation
rawhat = matrix(0,n,k)
yhat = matrix(0,n,k)
sdiff = matrix(0,n,k)
for (i in 2:n){
for (j in 1:(k-1)){
yhat[i,j]= phi[1,j] + t(d4logdata[(i-1),]) %*% phi[2:86,j]
}
rawhatv = rawdata[(i-1),1:(k-1)] * exp(yhat[i,1:(k-1)]/100) # back transform
yhat[i,k]=100*log(sum(rawhatv)/rawdata[(i-1),k])
rawhat[i,] = rawdata[(i-1),1:k] * exp(yhat[i,1:k]/100)
sdiff[i,] = exp(yhat[i,1:k]/100)
}
# Conduct our multiplier analysis
# The row we set 44 is 4(4 last observations to start forecasting) + 40(10 years horizon of forecasting)
multiraw = matrix(0,44,k)
multiraw[1:4,]=rawdata[(nrow(rawdata)-3):nrow(rawdata),]
multig = matrix(0,44,k)
multilevels = matrix(0,44,k-1) # matrix that saves the evolution of total employment in reaction to 1 percent point shock in each sector
multigrowth = matrix(0,44,k-1) # matrix that saves the evolution of employment growth in reaction to 1 percentage point shock in each sector
sector = 1
i = 5
j = 1
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
View(logdata)
View(multig)
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
multiraw[i,1:(k-1)] = multiraw[(i-4),1:(k-1)]*exp(multig[i,1:(k-1)]/100)
View(multiraw)
multiraw[i,k] = sum(multiraw[i,1:(k-1)])
multig[i,k]=100*log(multiraw[i,k]/multiraw[(i-4),k]) # ???? why here need to take log, is means log(y_t) - log(y_{t-4})
i = 6
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
View(multilevels)
for (sector in 1:(k-1)){
for (i in 5:44){
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
multiraw[i,1:(k-1)] = multiraw[(i-4),1:(k-1)]*exp(multig[i,1:(k-1)]/100)
multiraw[i,k] = sum(multiraw[i,1:(k-1)])
multig[i,k]=100*log(multiraw[i,k]/multiraw[(i-4),k]) # ???? why here need to take log, is means log(y_t) - log(y_{t-4})
}
multilevels[,sector]=multiraw[,k]
multigrowth[,sector]=multig[,k]   # suspect here will need to select k instead sector
}
# Elvis Yang
# June 2022
# This is the program computes the multipliers and contrafactural or scenario forecasting
library(matrixStats)
library(ggplot2)
library(zoo)
library(tidyverse)
library(dplyr)
library(stats)
library(readxl)
library(pracma)
library(tidyverse)
library(lubridate)
library(fpp3)
# INPUTS
# y  Time series
#p lags
# varagin There are the(optional) bootstrapping options
# 'parametric'   Draw residuals parametrically from the covariance matrix
# 'bootstrap_with _replacement'  Draw residuals randomly from the empirical residuals
# 'double_bootstrap'   Bias correction boostrap-after -bootstrap
# 'wild_bootstrap' Allws for hetroskedasticity by multiplying by a random variable
alldata <- readr::read_csv("ABSemp.csv")  |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date) |>
filter(Quarter <= yearquarter("2019 Q4"))
alldata <- alldata |>
select(-Quarter)
# generate the total amount of the data
rawdata <- as.matrix(alldata) # Remove the NA values due to the loading of the data.
logdata <- log(rawdata)
d4logdata <- 100*(logdata[5:nrow(logdata),]-logdata[1:(nrow(logdata)-4),]) %>% as.matrix()
summary(d4logdata)  # check summary to see if data are read correctly
N=dim(d4logdata)[2]
p=4
lambda=0.2 # shrinkage
maxhor=2 # maximum forecast horizon where we are imposing conditions
# generate the phi of your estimated model
#phi <- BVAR(d4logdata,p,lambda)
phi <- read.csv("phi_2.csv",header=FALSE) %>% as.matrix #estimated parameters produced by MATLAB code
n = nrow(d4logdata)
k = ncol(d4logdata)
# For users, you have to replace the numbers phi if you really want to build up another type of model
# The phi is produced using MATLAB MAIN.m file, please run that file to generate the estimated coefficients.
# Here the phi are divided to give four lags and one constant.
# phi[1,j] for constant, the rest are multiplied by the four lags and do the estimation
rawhat = matrix(0,n,k)
yhat = matrix(0,n,k)
sdiff = matrix(0,n,k)
for (i in 2:n){
for (j in 1:(k-1)){
yhat[i,j]= phi[1,j] + t(d4logdata[(i-1),]) %*% phi[2:86,j]
}
rawhatv = rawdata[(i-1),1:(k-1)] * exp(yhat[i,1:(k-1)]/100) # back transform
yhat[i,k]=100*log(sum(rawhatv)/rawdata[(i-1),k])
rawhat[i,] = rawdata[(i-1),1:k] * exp(yhat[i,1:k]/100)
sdiff[i,] = exp(yhat[i,1:k]/100)
}
# Conduct our multiplier analysis
# The row we set 44 is 4(4 last observations to start forecasting) + 40(10 years horizon of forecasting)
multiraw = matrix(0,44,k)
multiraw[1:4,]=rawdata[(nrow(rawdata)-3):nrow(rawdata),]
multig = matrix(0,44,k)
multilevels = matrix(0,44,k-1) # matrix that saves the evolution of total employment in reaction to 1 percent point shock in each sector
multigrowth = matrix(0,44,k-1) # matrix that saves the evolution of employment growth in reaction to 1 percentage point shock in each sector
for (sector in 1:(k-1)){
for (i in 5:44){
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
multiraw[i,1:(k-1)] = multiraw[(i-4),1:(k-1)]*exp(multig[i,1:(k-1)]/100)
multiraw[i,k] = sum(multiraw[i,1:(k-1)])
multig[i,k]=100*log(multiraw[i,k]/multiraw[(i-4),k]) # ???? why here need to take log, is means log(y_t) - log(y_{t-4})
}
multilevels[,sector]=multiraw[,k]
multigrowth[,sector]=multig[,k]   # suspect here will need to select k instead sector
}
View(multilevels)
# Elvis Yang
# June 2022
# This is the program computes the multipliers and contrafactural or scenario forecasting
library(matrixStats)
library(ggplot2)
library(zoo)
library(tidyverse)
library(dplyr)
library(stats)
library(readxl)
library(pracma)
library(tidyverse)
library(lubridate)
library(fpp3)
# INPUTS
# y  Time series
#p lags
# varagin There are the(optional) bootstrapping options
# 'parametric'   Draw residuals parametrically from the covariance matrix
# 'bootstrap_with _replacement'  Draw residuals randomly from the empirical residuals
# 'double_bootstrap'   Bias correction boostrap-after -bootstrap
# 'wild_bootstrap' Allws for hetroskedasticity by multiplying by a random variable
alldata <- readr::read_csv("ABSemp.csv")  |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date) |>
filter(Quarter <= yearquarter("2019 Q4"))
alldata <- alldata |>
select(-Quarter)
# generate the total amount of the data
rawdata <- as.matrix(alldata) # Remove the NA values due to the loading of the data.
logdata <- log(rawdata)
d4logdata <- 100*(logdata[5:nrow(logdata),]-logdata[1:(nrow(logdata)-4),]) %>% as.matrix()
summary(d4logdata)  # check summary to see if data are read correctly
N=dim(d4logdata)[2]
p=4
lambda=0.2 # shrinkage
maxhor=2 # maximum forecast horizon where we are imposing conditions
# generate the phi of your estimated model
#phi <- BVAR(d4logdata,p,lambda)
phi <- read.csv("phi_2.csv",header=FALSE) %>% as.matrix #estimated parameters produced by MATLAB code
n = nrow(d4logdata)
k = ncol(d4logdata)
# For users, you have to replace the numbers phi if you really want to build up another type of model
# The phi is produced using MATLAB MAIN.m file, please run that file to generate the estimated coefficients.
# Here the phi are divided to give four lags and one constant.
# phi[1,j] for constant, the rest are multiplied by the four lags and do the estimation
rawhat = matrix(0,n,k)
yhat = matrix(0,n,k)
sdiff = matrix(0,n,k)
for (i in 2:n){
for (j in 1:(k-1)){
yhat[i,j]= phi[1,j] + t(d4logdata[(i-1),]) %*% phi[2:86,j]
}
rawhatv = rawdata[(i-1),1:(k-1)] * exp(yhat[i,1:(k-1)]/100) # back transform
yhat[i,k]=100*log(sum(rawhatv)/rawdata[(i-1),k])
rawhat[i,] = rawdata[(i-1),1:k] * exp(yhat[i,1:k]/100)
sdiff[i,] = exp(yhat[i,1:k]/100)
}
# Conduct our multiplier analysis
# The row we set 44 is 4(4 last observations to start forecasting) + 40(10 years horizon of forecasting)
multiraw = matrix(0,44,k)
multiraw[1:4,]=rawdata[(nrow(rawdata)-3):nrow(rawdata),]
multig = matrix(0,44,k)
multilevels = matrix(0,44,k-1) # matrix that saves the evolution of total employment in reaction to 1 percent point shock in each sector
multigrowth = matrix(0,44,k-1) # matrix that saves the evolution of employment growth in reaction to 1 percentage point shock in each sector
sector =1
for (i in 5:44){
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
multiraw[i,1:(k-1)] = multiraw[(i-4),1:(k-1)]*exp(multig[i,1:(k-1)]/100)
multiraw[i,k] = sum(multiraw[i,1:(k-1)])
multig[i,k]=100*log(multiraw[i,k]/multiraw[(i-4),k]) # ???? why here need to take log, is means log(y_t) - log(y_{t-4})
}
multilevels[,sector]=multiraw[,k]
multigrowth[,sector]=multig[,k]   # suspect here will need to select k instead sector
View(multilevels)
View(multiraw)
View(multig)
View(multigrowth)
for (sector in 1:(k-1)){
for (i in 5:44){
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
multiraw[i,1:(k-1)] = multiraw[(i-4),1:(k-1)]*exp(multig[i,1:(k-1)]/100)
multiraw[i,k] = sum(multiraw[i,1:(k-1)])
multig[i,k]=100*log(multiraw[i,k]/multiraw[(i-4),k]) # ???? why here need to take log, is means log(y_t) - log(y_{t-4})
}
multilevels[,sector]=multiraw[,k]
multigrowth[,sector]=multig[,k]   # suspect here will need to select k instead sector
}
View(multigrowth)
multipliers = colSums(multigrowth)/4 # division by 4 is necessary because of seasonal differences
View(multipliers)
multipliers
multipliers = colSums(multigrowth)/4 # division by 4 is necessary because of seasonal differences
mpers = colCumsums(multigrowth[5:44,])/4 #colCumsums() is a function in matrixStats package
shares=colSums(rawdata[(nrow(rawdata)-3):nrow(rawdata),1:84])/sum(rawdata[(nrow(rawdata)-3):nrow(rawdata),85]) #sector shares estimated like this to eliminate the effect of seasonality
mtplers <- rbind(shares,mpers)
View(mtplers)
View(phi)
View(mtplers)
View(mpers)
View(mtplers)
View(mtplers)
rowsum(mtplers)
sum(mtplers[1:,])
sum(mtplers[c(1:ncol(mtplers)),])
mtplers[c(1:ncol(mtplers)),]
mtplers[c(1:84),]
mtplers[,1:84]
sum(mtplers[1,])
max(mtplers[1,])
View(mtplers)
mtplers |> filter(mtplers[1,] == 0.0693974)
View(phi)
# The row we set 44 is 4(4 last observations to start forecasting) + 40(10 years horizon of forecasting)
source("~/Desktop/hon_proj/Disaggregated_Employment/Spilover/forecast_onelag.R", echo=TRUE)
multiraw = matrix(0,44,k)
multiraw[1:4,]=rawdata[(nrow(rawdata)-3):nrow(rawdata),]
multig = matrix(0,44,k)
multilevels = matrix(0,44,k-1) # matrix that saves the evolution of total employment in reaction to 1 percent point shock in each sector
multigrowth = matrix(0,44,k-1) # matrix that saves the evolution of employment growth in reaction to 1 percentage point shock in each sector
for (sector in 1:(k-1)){
for (i in 5:44){
for (j in 1:(k-1)){
multig[i,j]= phi[1,j] + multig[(i-1),]%*%phi[(2:86),j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
multiraw[i,1:(k-1)] = multiraw[(i-4),1:(k-1)]*exp(multig[i,1:(k-1)]/100)
multiraw[i,k] = sum(multiraw[i,1:(k-1)])
multig[i,k]=100*log(multiraw[i,k]/multiraw[(i-4),k]) # ???? why here need to take log, is means log(y_t) - log(y_{t-4})
}
multilevels[,sector]=multiraw[,k]
multigrowth[,sector]=multig[,k]   # suspect here will need to select k instead sector
}
multipliers = colSums(multigrowth)/4 # division by 4 is necessary because of seasonal differences
mpers = colCumsums(multigrowth[5:44,])/4 #colCumsums() is a function in matrixStats package
shares=colSums(rawdata[(nrow(rawdata)-3):nrow(rawdata),1:84])/sum(rawdata[(nrow(rawdata)-3):nrow(rawdata),85]) #sector shares estimated like this to eliminate the effect of seasonality
mtplers <- rbind(shares,mpers)
View(mtplers)
View(phi)
