for(i in 1:p){
rnmb<-p+1-i
cnmb<-nrow(y)-i
Z<-y[rnmb:cnmb,]
X<-cbind(X,Z)
}
# constant to stack at last
X<-cbind(X,ones(T,1))
# This is to set prior
small_sig2=zeros(N,1)
Stack_AR_coeff=zeros(p,N)
for(i in c(1:N)){
#calculate variance for each equation to set pror
#by fitting an AR(4) per equation
c(~,small_sig2[i,1])=olsvar(y[,i],4)
alldata <- readr::read_csv("ABSemp.csv")
# generate the total amount of the data
rawdata <- as.matrix(alldata) # Remove the NA values due to the loading of the data.
logdata <- log(rawdata)
d4logdata <- 100*(logdata[5:nrow(logdata),]-logdata[1:(nrow(logdata)-4),]) %>% as.matrix()
summary(d4logdata)  # check summary to see if data are read correctly
N=dim(d4logdata)[2]
p=4
lambda=0.2 # shrinkage
maxhor=2 # maximum forecast horizon where we are imposing conditions
# generate the phi of your estimated model
#phi <- BVAR(d4logdata,p,lambda)
phi <- read.csv("phi.csv",header=FALSE) %>% as.matrix #estimated parameters produced by MATLAB code
n = nrow(d4logdata)
k = ncol(d4logdata)
# For users, you have to replace the numbers phi if you really want to build up another type of model
# The phi is produced using MATLAB MAIN.m file, please run that file to generate the estimated coefficients.
# Here the phi are divided to give four lags and one constant.
# phi[1,j] for constant, the rest are multiplied by the four lags and do the estimation
rawhat = matrix(0,n,k)
yhat = matrix(0,n,k)
sdiff = matrix(0,n,k)
for (i in 5:n){
for (j in 1:(k-1)){
yhat[i,j]= phi[1,j] + t(d4logdata[(i-1),]) %*% phi[2:86,j] + t(d4logdata[(i-2),]) %*% phi[87:171,j] + t(d4logdata[(i-3),]) %*% phi[172:256,j] + t(d4logdata[(i-4),]) %*%
phi[257:341,j] # y_t = y_{t-1}+y_{t-1}+y{t-3}+y_{t-4}
}
rawhatv = rawdata[(i-4),1:(k-1)] * exp(yhat[i,1:(k-1)]/100) # back transform
yhat[i,k]=100*log(sum(rawhatv)/rawdata[(i-4),k])
rawhat[i,] = rawdata[(i-4),1:k] * exp(yhat[i,1:k]/100)
sdiff[i,] = exp(yhat[i,1:k]/100)
}
# Perform out for sample forecast use the rawhat(estimation) to do
# Steps are similar use the last four observation to fit the phi above to generate t+1 forecast
# Testing model using error measurements MAPE and Scaled errors
newraw <- rawdata[9:nrow(rawdata),] # Define the actual values of forecast
rawhat1 <- rawhat[5:nrow(rawhat),]
error <- (newraw - rawhat1)
train_err <- matrix(0,n,k)
# Scale-dependent errors
MAE = mean(abs(error))
RMSE = sqrt(mean(error))
# Percentage error
for(i in 1:(n-4)){
for (j in 1:k){
train_err[i,j] <- 100 * as.vector(error[i,j]) / as.vector(newraw[i,j]) # Percentage error
}
}
# To calculate the MAPE we apply the formula as   sum(abs(y_t - \hat{y_t}/y_t))/(n)
MAPE = sum(abs(train_err))/(n-4 * k )
# Scaled error -- Hyndman & Koehler(2006) see [https://otexts.com/fpp3/accuracy.html]
# First: Define the scaled error yt - y_{t-4} as sdiff and calculated in previous steps
# sdiff = yt - y_{t-4}
# Second, calculate the denominator as for seasonal time series m=4
denom = sum(sdiff)/(n-4)
# Third calculate the q_j
qj = matrix(0,n,k)
for(a in 1:i){
for (b in 1:k){
qj[a,b] = error[a,b]/denom
}
}
MASE = mean(abs(qj))
RMSSE = sqrt(mean(qj^2))
# Conduct our multiplier analysis
multiraw = matrix(0,44,k) # ELVIS -- why here we set the number equals to 44
multiraw[1:4,] = rawdata[(nrow(rawdata)-3):nrow(rawdata),]
multig = matrix(0,44,k)
multilevels = matrix(0,44,k-1) # matrix that saves the evolution of total employment in reaction to 1 percent point shock in each sector
multigrowth = matrix(0,44,k-1) # matrix that saves the evolution of employment growth in reaction to 1 percentage point shock in each sector
for (sector in 1:(k-1)){
for (i in 5:44){
for (j in 1:(k-1)){
multig[i,j]= multig[(i-1),]%*%phi[(2:86),j] + multig[(i-2),]%*%phi[87:171,j] + multig[(i-3),] %*% phi[172:256,j] + multig[(i-4),] %*% phi[257:341,j]
if (i==5 & j==sector) {multig[i,j]=multig[i,j]+1}
}
multiraw[i,1:(k-1)] = multiraw[(i-4),1:(k-1)]*exp(multig[i,1:(k-1)]/100)
multiraw[i,k] = sum(multiraw[i,1:(k-1)])
multig[i,k]=100*log(multiraw[i,k]/multiraw[(i-4),k])
}
multilevels[,sector]=multiraw[,k]
multigrowth[,sector]=multig[,k]
}
multipliers = colSums(multigrowth)/4 # division by 4 is necessary because of seasonal differences
mpers = colCumsums(multigrowth[5:44,])/4 #colCumsums() is a function in matrixStats package
shares=colSums(rawdata[(nrow(rawdata)-3):nrow(rawdata),1:84])/sum(rawdata[(nrow(rawdata)-3):nrow(rawdata),85]) #sector shares estimated like this to eliminate the effect of seasonality
write.csv(file="multipliers.csv",rbind(shares,mpers))
multiplier <- rbind(shares,mpers)
View(multiplier)
library(fpp3)
# Chunk 1
library(fpp3)
# Chunk 2
employ<- read.csv("ABSemp.csv")
View(employ)
View(employ)
ts_employ <- employ |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date) |>
as_tsibble(index = Quarter)
View(ts_employ)
ts_employ <- ts_employ |>
filter(Quarter = "2019 Q4")
ts_employ <- ts_employ |>
filter(Quarter == "2019 Q4")
ts_employ <- ts_employ |>
filter(Quarter <= "2019 Q4")
View(ts_employ)
ts_employ <- ts_employ |>
filter(Quarter <= "2019 Q4")
ts_employ <- ts_employ |>
filter(Quarter <= "2019 Q4")
ts_employ <- ts_employ |>
filter(Quarter <= "2019 Q4")
ts_employ <- ts_employ |>
filter(Quarter <= yearquarter("2019 Q4"))
View(ts_employ)
fc_model <- ts_emplong |>
model(stepwise = ARIMA(Employment))
# Chunk 1
library(fpp3)
# Chunk 2
employ<- read.csv("ABSemp.csv")
# Chunk 3
# employ <- employ |>
#   mutate(Month = yearmonth(Date)) |>
#   select(-Date)
ts_employ <- employ |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date) |>
as_tsibble(index = Quarter)
ts_employ <- ts_employ |>
filter(Quarter <= yearquarter("2019 Q4"))
# Chunk 4
ts_emplong <- ts_employ |>
pivot_longer(cols = c(-Quarter) , names_to = "Industry", values_to = "Employment")
fc_model <- ts_emplong |>
model(stepwise = ARIMA(Employment))
fc_emp<- fc_model |>
forecast(h=10)
View(fc_model)
test <- ts_employ[21,]
test <- ts_employ[-21,]
ts_employ <- ts_employ |>
filter(Quarter <= yearquarter("2019 Q4"))
# Chunk 1
library(fpp3)
# Chunk 2
employ<- read.csv("ABSemp.csv")
# employ <- employ |>
#   mutate(Month = yearmonth(Date)) |>
#   select(-Date)
ts_employ <- employ |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date) |>
as_tsibble(index = Quarter)
pre_2019 <- ts_employ |>
filter(Quarter <= yearquarter("2019 Q4"))
training <- pre_2019[-21,]
View(training)
training <- pre_2019[1:120,]
training <- pre_2019[1:120,]
test <- pre_2019[121:nrow(pre2019)]
test <- pre_2019[121:nrow(pre2019)]
test <- pre_2019[121:nrow(pre_2019)]
test <- pre_2019[121:nrow(pre_2019),]
# Chunk 1
library(fpp3)
# Chunk 2
employ<- read.csv("ABSemp.csv")
# Chunk 3
# employ <- employ |>
#   mutate(Month = yearmonth(Date)) |>
#   select(-Date)
ts_employ <- employ |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date) |>
as_tsibble(index = Quarter)
pre_2019 <- ts_employ |>
filter(Quarter <= yearquarter("2019 Q4"))
training <- pre_2019[1:120,]
test <- pre_2019[121:nrow(pre_2019),]
training <- training |>
pivot_longer(cols = c(-Quarter) , names_to = "Industry", values_to = "Employment")
fc_model <- training |>
model(stepwise = ARIMA(Employment))
fc_emp<- fc_model |>
forecast(h=10)
View(fc_model)
View(fc_emp)
fc_model <- training |>
model(stepwise = ARIMA(Employment))
# Chunk 1
library(fpp3)
# Chunk 2
employ<- read.csv("ABSemp.csv")
# Chunk 3
# employ <- employ |>
#   mutate(Month = yearmonth(Date)) |>
#   select(-Date)
ts_employ <- employ |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date) |>
as_tsibble(index = Quarter)
pre_2019 <- ts_employ |>
filter(Quarter <= yearquarter("2019 Q4"))
# Chunk 4
training <- pre_2019[1:120,]
test <- pre_2019[121:nrow(pre_2019),]
# Chunk 5
training <- training |>
pivot_longer(cols = c(-Quarter) , names_to = "Industry", values_to = "Employment")
fc_model <- training |>
model(stepwise = ARIMA(Employment))
fc_emp<- fc_model |>
forecast(h=21)
fc_emp<- fc_model |>
forecast(h=21)
View(fc_emp)
fc_emp |>
pivot_wider(cols = c(-Date))
fc_emp |>
pivot_wider(-Date)
??pivot_wider
fc_emp |>
pivot_wider(-Date)
fc_emp |>
pivot_wider(-Date, names_from = "Industry", values_from = "Employment")
fc_emp |>
pivot_wider(-Date, names_from = "Quarter", values_from = ".mean")
fc_emp |>
pivot_wider(-Date, names_from = "Industry", values_from = ".mean")
fc_emp |>
pivot_wider(-Quarter, names_from = "Industry", values_from = ".mean")
fc_emp |>
pivot_wider( names_from = "Industry", values_from = ".mean")
fc_emp |>
pivot_wider( names_from = "Industry", values_from = ".mean")
fc_emp |>
pivot_wider( names_from = "Industry", values_from = ".mean")
View(fc_emp)
fc_emp |>
pivot_wider( names_from = "Industry", values_from = ".mean")
fc_model <- training |>
model(stepwise = ARIMA(Employment),
ETS = ETS(Employment))
fc_emp |>
accuracy()
fc_emp |>
accuracy(training)
fc_emp |>
accuracy(training)%>%
select(.model, RMSE:MAPE)
fc_emp |>
accuracy(test)%>%
select(.model, RMSE:MAPE)
fc_emp |>
accuracy(test)%>%
select(.model, RMSE:MAPE)
fc_emp |>
accuracy(training)%>%
select(.model, RMSE:MAPE)
View(training)
error <-  fc_emp |>
accuracy(training)%>%
select(.model, RMSE:MAPE)
View(error)
error <-  fc_emp |>
accuracy(test)%>%
select(.model, RMSE:MAPE)
View(test)
test <- test |>
pivot_longer(cols = c(-Quarter) , names_to = "Industry", values_to = "Employment")
error <-  fc_emp |>
accuracy(test)%>%
select(.model, RMSE:MAPE)
View(employ)
View(error)
fc_model <- training |>
model(stepwise = ARIMA(Employment),
ETS = ETS(Employment))
fc_emp<- fc_model |>
forecast(h=21)
error <-  fc_emp |>
accuracy(test)%>%
select(.model, RMSE:MAPE)
View(error)
error |>
filter(.model == "ETS")
ETS_mod <- error |>
filter(.model == "ETS")
View(ETS_mod)
sum(ETS_mod)
summary(ETS_mod)
# Chunk 1
library(fpp3)
# Chunk 2
employ<- read.csv("ABSemp.csv")
# Chunk 3
# employ <- employ |>
#   mutate(Month = yearmonth(Date)) |>
#   select(-Date)
ts_employ <- employ |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date) |>
as_tsibble(index = Quarter)
pre_2019 <- ts_employ |>
filter(Quarter <= yearquarter("2019 Q4"))
# Chunk 4
training <- pre_2019[1:120,]
test <- pre_2019[121:nrow(pre_2019),]
# Chunk 5
training <- training |>
pivot_longer(cols = c(-Quarter) , names_to = "Industry", values_to = "Employment")
test <- test |>
pivot_longer(cols = c(-Quarter) , names_to = "Industry", values_to = "Employment")
fc_model <- training |>
model(stepwise = ARIMA(Employment),
ets = ETS(Employment),
mean = MEAN(Employment))
fc_emp<- fc_model |>
forecast(h=21)
error <-  fc_emp |>
accuracy(test)%>%
select(.model, RMSE:MAPE)
View(error)
ETS_mod <- error |>
filter(.model == "ets")
colSums(ETS_mod)
View(ETS_mod)
ETS_RMSE <- rowSums(ETS_mod$RMSE)
ETS_RMSE <- rowSums(as.matrix(ETS_mod$RMSE))
ETS_RMSE <- colSums(as.matrix(ETS_mod$RMSE))
ETS_MAPE <- colSums(as.matrix(ETS_mod$MAPE))
ETS_MAPE <- colSums(as.matrix(ETS_mod$MAPE)) / 85
ETS_MAPE <- colSums(as.matrix(ETS_mod$MAPE)) / ncol(ETS_mod)
ETS_MAPE <- colSums(as.matrix(ETS_mod$MAPE)) / nrow(ETS_mod)
ARIMA_MAPE <- colSums(as.matrix(ARIMA_mod$MAPE)) / nrow(ARIMA_mod)
ARIMA_mod <- error |>
filter(.model == "stepwise")
ARIMA_MAPE <- colSums(as.matrix(ARIMA_mod$MAPE)) / nrow(ARIMA_mod)
View(fc_model)
MEAN_mod <- error |>
filter(.model == "mean")
MEAN_mod <- colSums(as.matrix(MEAN_mod$MAPE)) / nrow(MEAN_mod)
MEAN_MAPE <- colSums(as.matrix(MEAN_mod$MAPE)) / nrow(MEAN_mod)
# Chunk 1
library(fpp3)
# Chunk 2
employ<- read.csv("ABSemp.csv")
# Chunk 3
# employ <- employ |>
#   mutate(Month = yearmonth(Date)) |>
#   select(-Date)
ts_employ <- employ |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date) |>
as_tsibble(index = Quarter)
pre_2019 <- ts_employ |>
filter(Quarter <= yearquarter("2019 Q4"))
# Chunk 4
training <- pre_2019[1:120,]
test <- pre_2019[121:nrow(pre_2019),]
# Chunk 5
training <- training |>
pivot_longer(cols = c(-Quarter) , names_to = "Industry", values_to = "Employment")
test <- test |>
pivot_longer(cols = c(-Quarter) , names_to = "Industry", values_to = "Employment")
# Chunk 6
fc_model <- training |>
model(stepwise = ARIMA(Employment),
ets = ETS(Employment),
mean = MEAN(Employment))
fc_emp<- fc_model |>
forecast(h=21)
error <-  fc_emp |>
accuracy(test)%>%
select(.model, RMSE:MAPE)
# Chunk 7
ETS_mod <- error |>
filter(.model == "ets")
ETS_MAPE <- colSums(as.matrix(ETS_mod$MAPE)) / nrow(ETS_mod)
# Chunk 8
ARIMA_mod <- error |>
filter(.model == "stepwise")
ARIMA_MAPE <- colSums(as.matrix(ARIMA_mod$MAPE)) / nrow(ARIMA_mod)
View(fc_model)
ARIMA_MASE <- colSums(as.matrix(ARIMA_mod$MASE)) / nrow(ARIMA_mod)
View(employ)
View(error)
error <-  fc_emp |>
accuracy(test
error <-  fc_emp |>
View(error)
error <-  fc_emp |>
accuracy(test)#%>%
View(error)
fc_model <- training |>
model(stepwise = ARIMA(Employment),
ets = ETS(Employment))
fc_emp<- fc_model |>
forecast(h=21)
error <-  fc_emp |>
accuracy(test)#%>%
#select(.model, RMSE:MAPE)
View(error)
View(error)
View(error)
error <-  fc_emp |>
accuracy(training)#%>%
orilong <- employ |>
pivot_longer(cols = c(-Quarter) , names_to = "Industry", values_to = "Employment")
View(employ)
orilong <- ts_employ |>
pivot_longer(cols = c(-Quarter) , names_to = "Industry", values_to = "Employment")
error <-  fc_emp |>
accuracy(orlong)#%>%
orlong <- ts_employ |>
pivot_longer(cols = c(-Quarter) , names_to = "Industry", values_to = "Employment")
error <-  fc_emp |>
accuracy(orlong)#%>%
View(error)
ARIMA_MASE <- colSums(as.matrix(ARIMA_mod$MASE)) / nrow(ARIMA_mod)
ARIMA_mod <- error |>
filter(.model == "stepwise")
ARIMA_MAPE <- colSums(as.matrix(ARIMA_mod$MAPE)) / nrow(ARIMA_mod)
ARIMA_MASE <- colSums(as.matrix(ARIMA_mod$MASE)) / nrow(ARIMA_mod)
ETS_MASE <- colSums(as.matrix(ETS_mod$MASE)) / nrow(ETS_mod)
ETS_mod <- error |>
filter(.model == "ets")
ETS_MAPE <- colSums(as.matrix(ETS_mod$MAPE)) / nrow(ETS_mod)
ETS_MASE <- colSums(as.matrix(ETS_mod$MASE)) / nrow(ETS_mod)
View(fc_model)
View(fc_model[[2]][[85]])
MEAN_MASE <- colSums(as.matrix(MEAN_MASE$MASE)) / nrow(MEAN_mod)
MEAN_mod <- error |>
filter(.model == "mean")
MEAN_MAPE <- colSums(as.matrix(MEAN_mod$MAPE)) / nrow(MEAN_mod)
MEAN_MASE <- colSums(as.matrix(MEAN_MASE$MASE)) / nrow(MEAN_mod)
fc_model <- training |>
model(stepwise = ARIMA(Employment),
ets = ETS(Employment),
mean = MEAN(Employment))
fc_emp<- fc_model |>
forecast(h=21)
error <-  fc_emp |>
accuracy(orlong)#%>%
#select(.model, RMSE:MAPE)
View(pre_2019)
library(fpp3)
employ<- read.csv("ABSemp.csv")
# employ <- employ |>
#   mutate(Month = yearmonth(Date)) |>
#   select(-Date)
ts_employ <- employ |>
mutate(Quarter = yearquarter(my(Date))) |>
select(-Date) |>
as_tsibble(index = Quarter)
pre_2019 <- ts_employ |>
filter(Quarter <= yearquarter("2019 Q4"))
training <- pre_2019[1:120,]
test <- pre_2019[121:nrow(pre_2019),]
orlong <- ts_employ |>
pivot_longer(cols = c(-Quarter) , names_to = "Industry", values_to = "Employment")
training <- training |>
pivot_longer(cols = c(-Quarter) , names_to = "Industry", values_to = "Employment")
test <- test |>
pivot_longer(cols = c(-Quarter) , names_to = "Industry", values_to = "Employment")
fc_model <- training |>
model(stepwise = ARIMA(Employment),
ets = ETS(Employment),
mean = MEAN(Employment))
fc_emp<- fc_model |>
forecast(h=21)
error <-  fc_emp |>
accuracy(orlong)#%>%
#select(.model, RMSE:MAPE)
View(fc_emp)
aaa <- mean(pre_2019$X01.Agriculture)
View(error)
MEAN_mod <- error |>
filter(.model == "mean")
MEAN_MAPE <- colSums(as.matrix(MEAN_mod$MAPE)) / nrow(MEAN_mod)
MEAN_MASE <- colSums(as.matrix(MEAN_MASE$MASE)) / nrow(MEAN_mod)
MEAN_mod <- error |>
filter(.model == "mean")
MEAN_MAPE <- colSums(as.matrix(MEAN_mod$MAPE)) / nrow(MEAN_mod)
MEAN_MASE <- colSums(as.matrix(MEAN_mod$MASE)) / nrow(MEAN_mod)
View(MEAN_mod)
MEAN_MASE <- colSums(as.matrix(MEAN_mod$MASE)) / nrow(MEAN_mod)
MEAN_RMSE <- colSums(as.matrix(MEAN_mod$RMSE)) / nrow(MEAN_mod)
View(fc_model)
View(fc_model[[4]][[6]])
View(fc_model[[4]][[2]])
fc_model[[4]][[2]][["data"]][["Employment"]]
??BVAR
mean(pre_2019$X01.Agriculture)
