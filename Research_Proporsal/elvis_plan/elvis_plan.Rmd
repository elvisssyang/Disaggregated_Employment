---
title: "Sectoral Employment Dynamics in Australia"
author:
- familyname: Yang 
  othernames: (Elvis) Zhixiang 
  address: Monash University
  email: zyan0056@student.monash.edu
  correspondingauthor: true
  qualifications: EBS Honours Student
department: Department of\newline Econometrics &\newline Business Statistics
organization: Honours \textbf{Research Plan}, supervised by \textbf{Farshid Vahid}
bibliography: references.bib
biblio-style: apa
linestretch: 1.5
output:
  monash::report:
    fig_caption: yes
    fig_height: 5
    fig_width: 8
    includes:
      in_header: preamble.tex
    keep_tex: yes
    number_sections: yes
    citation_package: biblatex
    toc: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache=TRUE, messages=FALSE, warning=FALSE)
library(ggplot2)
library(tidyverse)
```

\graphicspath{ {/Users/elvisyang/Desktop/Sectoral Employment Forecsating /Research_Proporsal/elvis_plan/figure} }

# Introduction

The COVID-19 pandemic has had a massive effect on economies around the world. Across different countries, millions of workers were furloughed or even lost their jobs as businesses struggled to survive [@ny2020]. Same situation happened in Australia, due to more restrictions, many businesses closed their doors, while employees were working with less hours or being dismissed by companies. As a result of the continuous "lockdown" periods in 2020, the estimates made by the Australian Bureau of Statistics [@ABS2021] concluded that 72% of business generated less revenue and the underemployment rate hit historically high with 13.8% by the end of April, 2020, only one month after the COVID-19 outbreak.

Our research is motivated by the lack of quantitative research on the employment of sub-sectors in Australia, as many studies have focused on the aggregated employment rate. A general problem of aggregated researches is the loss of hierarchical information, which may result in a biased conclusion or "a illusion of employment prosperity". Thus, a quantitative analysis of the sectoral employment and will overcome this problem, giving us a better scope to evaluate the impact of COVID-19 in Australia.

<!-- <KEEP EITHER ONE>  Our research is motivated by the lack of knowledge about the employment of sub-sector knowledge in Australia. @anderson2020 developed a multivariate time series in 19 sectors for Australia and stated in their research that "Manufacturing" and "Construction" have highest positive spillovers for the aggregate economy. However, their research are limited due to the lack of sub-sector knowledge, which may have some detailed information within each sector. Our reserach plan is to expand their work to 87 sectors. A focus on the subsectoral employment and how different sub-sectors has responded to and recover from COVID-19 will give us a better scope to evaluate influences of COVID-19 in Australia.  -->

# Research aim and questions

This research will extend @anderson2020 by using data on 87 sub-sectors, instead of 19 they used. I will develop a model for the sub-sectors to evaluate the long run effect and the COVID-19 post-impacts. I will also provide an contrafactual analysis based on the assumption "if there is no pandemic". subsectoral data will provide us more information, which will assist in getting a better employment dynamics understanding of Australia.

The overall research aim is to provide estimates of subsectoral employment based on historical data. Specifically, my goals are: 

1. To build up a time series model of employment in 87 sectors of the Australian economy

1. To use this model to conduct our contrafactual analysis. 

3. To use this model to determine which sectors ave the highest impact on employment growth in the long run.


\newpage

# Review of literature

Our review of literature mainly focuses on two areas:

1.  The COVID-19 sectoral impacts and modelling to Economies.

2.  Modelling of large numbers of time series.

## Sectoral Impact for COVID-19 to Economies

Existing studies have focused on the evaluation of impacts of COVID-19 on board sectors of large economies such as the US and Europe. @ludvigson2020covid developed a disaster series to translate the macroeconomic impact of costly and deadly disasters in recent US history and modelled as sectoral shock to predict COVID-19, concluding that the shock would lead to a cumulative loss of 20% in industrial production, 39% in service sector and also reduce the US GDP by 12.75 per cent at the end of 2020. @gregory2020pandemic conducted simulations under different scenarios via a search theoretic model using US data and found the recovery in US is L-shaped, with employment remaining lower than the pre-covid for a long period. They also extended their studies at disaggregated level of 20 sectors, showing that "arts and entertainment" and "accommodation and food services" sectors would have the biggest shock during the pandemic.

<!-- @berger2020nowcasting also mentioned that a fall of 10.7 percent of output gap for US in third quarter.  -->

In Australia, @anderson2020 developed a multivariate time series for 19 main sectors in Australia (as a small open economy) using a Bayesian VARX model. Their research concluded that "Manufacturing" and "Construction" have highest positive spillovers for the aggregate economy. Meanwhile, they also applied a "conditional forecasting" method proposed by @waggoner1999 to simulate different scenarios for pandemic in Australia. However, this research does not use the most disaggregted level in Australia (sub-sectors of main sectors), which can be extremely useful in macroeconomic analysis.

<!-- should I put the part 1 last part here ??? for @anderson2020 or keep the existing one -->

## Modelling

### Baysian VAR

Literature of multivariate, large-size data tend to rely on Bayesian Vector Autoregression model(BVAR) [e.g. @anderson2020; @litterman1986; @banbura2010large]. The BVAR model is attractive because it allows us to estimate a large number of parameters, when sample size is not large, in a statistically coherent way.[@litterman1986;@wozniak2016bayesian].

In order to utilize the Bayesian VAR estimators and decrease the weight of hte lagged variable with the lag length, @litterman1979 proposed the Minnesota Prior by forcing the means of parameters 'centered' as a random walk. The mean on its first own lag is set to unity and the rest are set to zero so that (a) the most recent lag should provide more information than distant lags. (b) own lags should explain more than the lags of other variables.

### Improvement of BVAR

The literature suggests that a significant improvement can be made in the large BVAR dynamic model by imposing a stronger shrinkage parameter [@banbura2010large; @litterman1986]. @robertson1999vector and @kadiyala1997 proposed a normal inverted Wishart prior which retains the principal of Minnesota prior. Meanwhile, @banbura2010large suggested an easier way to apply the Minnesota prior via adding dummy observations in the BVAR system.

# Data collection and exploratory analysis

## Data Introduction

<!-- Find out some points about the data especially focusing on 19 to 87 comparison , identify the advantage of using 87 sectors rather than 19 sectors  -->

Our data source is the ABS Employment by industry subdivision of main job [@ABS2022], which records employment (measured in $\bf{'000}$) by the ANZSIC industry sub-division of their main jobs from $1984:Q4$ to $2021:Q4$. Our data structure is provided via Figure \ref{fig:anzsic}.

Although seasonally adjusted data is available in [@ABS2022], I will work with original data to capture any possible changes in seasonal patterns. I an seasonally difference will be applied to the logarithm of the original series in order to make it stationary and eliminate seasonality, which will make it easier to conduct further steps.

## Priliminary Exploratory Data Analysis

\newpage

Figure \ref{fig:19} illustrates the changes of raw data for 19 sectors in a more disaggregated manner. Due to the closedown of businesses and travel bans on 2020:Q2, we can observe that the number dropped substaincially (from around 13200 to 12200 on $2020:Q2$). Most industries behaved similarly with significant changes shown in Figure \ref{fig:19} . Comparing with the previous data of these industries, Accommodation&Food, Media&telecom and Administrative industries have experienced a severe loss of employment and have not fully recovered to the pre-covid level. However, industries like Financial and Electricity, Gas show an continuously increase trend as before.

Meanwhile, at 87 sub-sector level (the most disaggregated) in Table \ref{fig:comp}, we can conclude that the Food and Beverage Service experienced a severe shock after the lockdown, following by Heritage Activities and Other Store-Based Retailing.Figure \ref{fig:87} demonstrates the performance of each industry in the most disaggregated level, we can see sub-sectors we mentioned before have shown huge decreases in employment. It further proves that the employment decreases hugely in those sub-sectors mentioned before.

Nevertheless, there is a draw back of sectoral employment by comparing Figure \ref{fig:19} and Figure \ref{fig:87}, that is subsectoral dynamics may not be homogeneous. For some industries in these two figures, the huge changes are driven by some dominant sub-sectors. For example, in 19 sectoral level we may believe that all of the subsectors experienced a large shock by only looking their aggregated performance for Construction sector. (see Figure \ref{fig:19}). However, the reality is while Construction sector is decreasing, its sub-sectors 20.Building Construction and and 31.Heavy and civil engineering Construction increased(see Figure \ref{fig:87}). This means that not all sub-sectors suffered from the COVID-19 even the overall industry got influenced.

```{=tex}
\begin{figure}[t]
\includegraphics[scale=0.2]{Comparison}
\centering
\caption{The highest and lowest five sub-sectors' employment change in (10000) at 2020:Q2}
\label{fig:comp}
\end{figure}
```

# Methdology

## Proposed Model

I plan to use a Bayesian VARX model based on a method proposed by @anderson2020. In the model, each sector is affected by the lags of sectoral growth and a lag of the total employment growth. The lag of aggregate employment growth act as an economy-wide factor which will affect each sector.

Under the assumption that the structure of Australian economy will not change during the COVID-19, we suggest the BVAR model as

$$
\begin{aligned}
\textbf{y}_t=\textbf{c}+\textbf{A}_1 \textbf{y}_{t-1}+\textbf{A}_2\textbf{y}_{t-2}+\textbf{A}_3\textbf{y}_{t-3}+\textbf{A}_4\textbf{y}_{t-4}+\bf{\Gamma}\textbf{x}_{t-1}+\bf{u}_t
\end{aligned}
$$

where $\bf{y}_t$ is an $87\times1$ vector of subsectoral employment growth rate at time $t$ and $\bf{x}_{t-1}$ is the $4\times1$ vector of 4 lags of the growth rate of aggregate employment (this vector of variables are predetermined at time $t$), **c** is a vector of constants, $\bf{A}_{1,2,3,4}$ are $87\times87$ parameter matrices. $\bf{\Gamma}$ is a $87\times4$ matrix and $\bf{u}_t$ is a vector of reduced form errors with the mean equals to zero and independent variance $\bf{u}_t \sim (0,\bf{\Sigma})$. (see Appendix)

## Prior and shrinkage

I plan to estimate the VARX using Bayesian methods by specifying a Minnesota prior [e.g. @anderson2020; @litterman1986; @robertson1999vector]. In order to set up the Minnesota prior in our BVAR model, @banbura2010large suggestes a nature conjugate Normal-Wishart prior that applies shrinkage to the VAR slope coefficients using a Minnesota-type prior.

$$
\begin{aligned}
&E[a_{j}^{jk}] = E[\gamma_{i}^j]=0\\
\\
&Var[a_j^{jk}]= 
\begin{cases}
\frac{\lambda^2}{i^2},&j=k\\
\frac{\lambda^2}{i^2}\frac{\sigma^2_{j}}{\sigma^2_k},& otherwise
\end{cases}\\
\\
&Var[\gamma_i^{j}]=\frac{\lambda^2}{i^2}\frac{\sigma^2_{j}}{\sigma^2_e}
\end{aligned}
$$

@banbura2010large stated that the natural conjugate Normal-Inverse-Wishart posterior moments can be calculated either analytically or though adding the dummy observations. I will use dummy observations to estimate the BVAR e.g.[@banbura2010large; @anderson2020; @wozniak2016bayesian]. An example completed by @anderson2020 will be given in the Appendix. After the estimation of Bayesian VAR and then amounts to conducting least squares, we can draw our VAR coefficients by solving the posterior mode and mean.

# Timeline and expected outcome

Table \ref{tab:timeline1} summarises the work done to date. Table \ref{tab:timeline2} maps out the plan for completing the thesis research.

It is expected that we will have an accurate multivariate BVAR model to forecast the scenario without COVID-19 based on the data of 87 sub-sectors before 2019. Then we have some

```{r timeline, results='asis'}
timeline = data.frame(Timeline = c("Week 2","Week 3","", "Week 4","", "Week 5", "Week 6", "Week 7","Week 8", "week 9"),
                      Tasks = c(" Background reading about Multivariate VAR model",
                                "Collect Sub-sectoral data from ABS website",
                                "Prepare materials reltaed to subsectoral employment evaluations",
                                "Prepare literature review related to BVAR model and setting priors",
                                "Analysis about the MATLAB code done by Andereson et al. (2020)",
                                "Read articles about Conditional Forecasting",
                                "Prepare the conditional forecasting coding and hierarchical forecasting",
                                "Exploratory data analysis on sectoral and subsectoral data",
                                "Select suitable plots and test softwares to prepare the proposal ",
                                "Write research proposal and prepare the first presentation"))


knitr::kable(timeline, "latex",
             caption = "Completed work",
             label = "timeline1",
             booktabs = TRUE,
             escape = FALSE)
  
```

```{r}
timeline = data.frame(Timeline = c("June - July", "August", "September", "October"),
                      Tasks = c("Modelling of subsectoral employment", "Train the model using pre-covid data with BVAR model","apply foreecasts for quarters between 2020 to 2022", "Write my thesis and prepare for the second presentation")) 

knitr::kable(timeline, "latex",
             caption = "Research plan",
             label = "timeline2",
             booktabs = TRUE,
             escape = FALSE) 
```

\newpage

# Acknowledgement

I would like to gratitude my supervisor Professor Farshid Vahid and my coordinator Professor Heather Anderson very much for their selfless support and devoted care along the way.

# Appendix

Here is an example of the BVAR estimation done by @anderson2020.

```{=tex}
\begin{align}
\textbf{y}_t&=\textbf{c}+\textbf{A}_1 \textbf{y}_{t-1}+\textbf{A}_2+\cdots+\textbf{A}_4\textbf{y}_{t-4}+\bf{\Gamma}_1\textbf{x}_{t-1}+\bf{u}_t\\
&=
\begin{bmatrix}
c_1\\
\vdots\\
c_2
\end{bmatrix}
+
\begin{bmatrix}
a_1^{11}&\cdots&a_1^{1n}&\cdots&a_4^{11}&\cdots&a_4^{1n}&\gamma_1^{1}&\cdots&\gamma_4^{1}\\
\vdots&\ddots&\vdots&\ddots&\vdots&\ddots&\vdots&\vdots&\ddots&\vdots\\
a_1^{n1}&\cdots&a_1^{nn}&\cdots&a_4^{n1}&\cdots&a_4^{nn}&\gamma_1^n&\cdots&\gamma_4^n\\
\end{bmatrix}
\begin{bmatrix}
\bf{y}_{t-1}\\
\vdots\\
\bf{y}_{t-4}\\
x_{t-1}\\
\vdots\\
x_{t-4}
\end{bmatrix}\\
&+
\begin{bmatrix}
u_{1,t}\\
\vdots\\
u_{n,t}
\end{bmatrix}\\
\end{align}
```
where $E(\bf{u}_t\bf{u}'_t)=\bf{\Sigma}$ and $E(\bf{u}_t\bf{u'}_{t-1})=0$. Here the $n$ represent the number of sectors (or in our case will be 87) and $c$represents the vector of constants. There are 4 lags included for the total employment $(x_{t-1},\cdots,x_{t-4})$ as predetermined variable at time t.

Here is an Minnesota prior example done by @anderson2020:

The Normal-Wishart prior distribution take the form of

$$
\begin{aligned}
&vec(\mathbf{\beta}|\Sigma)\sim N(vec(\bf{\beta_0}),\Sigma\otimes\Omega_0)\ and\\
&\Sigma\sim\mathbf{IW}(S_0,a_0)
\end{aligned}
$$ where we set the prior parameters and $a_0$ based on the prior setting. The expectation of $\Sigma$ being $diag(\sigma^2_1,\cdots,\sigma^2_n$. Then we implement our VAR by defining dummy observations

$$
\begin{aligned}
Y_d&=
\begin{pmatrix}
\bf0_{np+p,n}\\
\bf diag(\bf{\sigma_1,\cdots,\sigma_n})\\
\bf0_{1\times n}
\end{pmatrix}\\
X_d&=
\begin{pmatrix}
\bf{J_p}\otimes diag(\frac{\sigma_1}{\lambda}\cdots\frac{\sigma_n}{\lambda},\frac{\sigma_e}{\lambda})&\bf0_{(np+p)\times1}\\
\bf 0_{n,np+p}&\bf 0_{n\times1}
\\
\bf 0_{1,np+p}&\bf \epsilon
\end{pmatrix}
\end{aligned}
$$ where

$$
\begin{aligned}
\bf{J_p}=diag(1,\cdots,p)\\
\bf{S_0}=(Y_d-X_d\times B_0)'(Y_d-X_dB_0)\\
\bf{B_0}=(X_d'X_d)^{-1}X_dY_d,\ \Omega_0=(X_d'X_d)^{-1}\  and\\
a_0=T_d-np-p-1\\
\end{aligned}
$$ where $T_d$ is the number of rows for both $\bf{Y}_d$ and $\bf{X}_d$.

We can get $$
\begin{aligned}
\bf{Y^*}=\bf{X^*}\bf{\beta}+\bf{\mu}^*\ \ \  where: \\
\bf{Y^*}=[\bf{Y'},\bf{Y'_d}]';\ \bf{X^*}=[\bf{X'},\bf{X'_d}]';\ \bf{\mu^*}=[\bf{\mu'},\bf{\mu'_d}]'
\end{aligned}
$$

Then we can estimating the BVAR by conducting an least square regression of $Y^*$ on$X^*$. The posterior distribution then have the form of

$$
\begin{aligned}
&vec(\mathbf{\beta})|\Sigma,Y\sim N(vec(\bf{\tilde\beta}),\Sigma\otimes(\bf{X^*}'\bf{X^*})^{-1})\ and\\
&\Sigma|Y\sim\mathbf{IW}(\tilde\Sigma,T_d+T-np+2)
\end{aligned}
$$ where $\bf{\tilde\beta} =(X*'X*)^{-1}X^{*'}Y^*$ and $\tilde\Sigma=(\bf{Y^*}-\bf{X^*}\bf{\tilde\beta})'(\bf{Y^*}-\bf{X^*}\bf{\tilde\beta})$

\newpage

```{=tex}
\begin{figure}[t]
\includegraphics[scale=0.6]{free_19}
\centering
\caption{Employment('000) of 19 sectors in Australia from 2019:Q1 to 2021:Q4}
\label{fig:19}
\end{figure}
```
```{=tex}
\begin{figure}[t]
\includegraphics[scale=0.5]{free_87}
\centering
\caption{Employment('000) of 87 sub-sectors in Australia from 2019:Q1 to 2021:Q4}
\label{fig:87}
\end{figure}
```
```{=tex}
\begin{figure}[t]
\includegraphics[scale=0.5]{ANZSIC}
\centering
\caption{Australian Industry Pamamid plot by (ANZSIC)}
\label{fig:anzsic}
\end{figure}
```
\clearpage
